{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reemaalt/Detection-of-Hallucination-in-Arabic/blob/main/Semantic_Entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-CbnTf8Ivac",
        "outputId": "3fbec137-dfcc-491d-c7c5-e1af9e33ba17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) N\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `week1 test` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `week1 test`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcBbLGoZCZUP",
        "outputId": "76e9cc8c-df34-4ba9-e414-58dcd6a4f9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Semantic Entropy code Based on the original implementation by the new githup\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from functools import lru_cache\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import ElectraTokenizerFast, ElectraForSequenceClassification, AutoModelForCausalLM, AutoTokenizer\n",
        "from google.colab import files\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "# Set up device and logging\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize TensorFlow and PyTorch operations\n",
        "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"1\"\n",
        "os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\n",
        "os.environ[\"TF_GPU_THREAD_COUNT\"] = \"4\"\n",
        "\n",
        "# For PyTorch\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision('high')"
      ],
      "metadata": {
        "id": "gGbwpbMF5lbR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDVS2hTwDcwg"
      },
      "source": [
        "#EntailmentModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOm4n6WiGCbQ",
        "outputId": "92e8c8fb-b42e-473f-f584-10a87d7b960e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "#ues our trained fine-tunied model\n",
        "#get the finetuned model from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = \"/content/drive/My Drive/araelectra-nli-finetuned.zip\"  # Adjust the path if needed\n",
        "extract_path = \"/content/araelectra\"\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BtaTMvXqCvS3"
      },
      "outputs": [],
      "source": [
        "class ArabicEntailmentModel:\n",
        "    \"\"\"Arabic entailment checker using AraELECTRA model.\"\"\"\n",
        "    def __init__(self, model_path=\"/content/araelectra/araelectra-nli-finetuned\"):\n",
        "        \"\"\"Initialize the model with better caching.\"\"\"\n",
        "        print(\"Loading AraELECTRA model for Arabic entailment checking...\")\n",
        "        self.tokenizer = ElectraTokenizerFast.from_pretrained(model_path)\n",
        "        self.model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
        "        self.model = self.model.to(DEVICE)\n",
        "        self.model.eval()  # Set to evaluation mode\n",
        "\n",
        "        # More efficient cache implementation\n",
        "        self.cache_file = \"entailment_cache.pkl\"\n",
        "        self.cache = {}\n",
        "        self._load_cache()\n",
        "\n",
        "        # Add batch processing capabilities\n",
        "        self.batch_size = 16\n",
        "        print(\"AraELECTRA model loaded successfully\")\n",
        "\n",
        "    def _load_cache(self):\n",
        "        try:\n",
        "            if os.path.exists(self.cache_file):\n",
        "                with open(self.cache_file, 'rb') as f:\n",
        "                    self.cache = pickle.load(f)\n",
        "                print(f\"Loaded {len(self.cache)} cached entailment results\")\n",
        "        except Exception as e:\n",
        "            print(f\"Cache loading failed: {e}\")\n",
        "            self.cache = {}\n",
        "\n",
        "    def _save_cache(self):\n",
        "        try:\n",
        "            with open(self.cache_file, 'wb') as f:\n",
        "                pickle.dump(self.cache, f)\n",
        "        except Exception as e:\n",
        "            print(f\"Cache saving failed: {e}\")\n",
        "\n",
        "    def check_implications_batch(self, text_pairs):\n",
        "        \"\"\"Process multiple text pairs in one batch.\"\"\"\n",
        "        results = []\n",
        "        uncached_pairs = []\n",
        "        uncached_indices = []\n",
        "\n",
        "        # Check cache first\n",
        "        for i, (text1, text2) in enumerate(text_pairs):\n",
        "            cache_key = (text1, text2)\n",
        "            if cache_key in self.cache:\n",
        "                results.append(self.cache[cache_key])\n",
        "            else:\n",
        "                uncached_pairs.append((text1, text2))\n",
        "                uncached_indices.append(i)\n",
        "\n",
        "        # Process uncached pairs in batches\n",
        "        if uncached_pairs:\n",
        "            batch_results = []\n",
        "            for i in range(0, len(uncached_pairs), self.batch_size):\n",
        "                batch = uncached_pairs[i:i+self.batch_size]\n",
        "                batch_inputs = []\n",
        "\n",
        "                for text1, text2 in batch:\n",
        "                    encoded = self.tokenizer(\n",
        "                        text1,\n",
        "                        text2,\n",
        "                        padding=True,\n",
        "                        truncation=True,\n",
        "                        max_length=128,\n",
        "                        return_tensors=\"pt\"\n",
        "                    )\n",
        "                    batch_inputs.append({k: v.unsqueeze(0) for k, v in encoded.items()})\n",
        "\n",
        "                # Concatenate all inputs into one batch tensor\n",
        "                batch_tensors = {\n",
        "                    k: torch.cat([inp[k] for inp in batch_inputs], dim=0).to(DEVICE)\n",
        "                    for k in batch_inputs[0].keys()\n",
        "                }\n",
        "\n",
        "                # Process the batch\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.model(**batch_tensors)\n",
        "                    logits = outputs.logits\n",
        "                    probs = F.softmax(logits, dim=1)\n",
        "                    predictions = torch.argmax(probs, dim=1).tolist()\n",
        "\n",
        "                # Convert to correct format and cache results\n",
        "                for j, pred in enumerate(predictions):\n",
        "                    text1, text2 = batch[j]\n",
        "                    result_map = {0: 2, 1: 1, 2: 0}\n",
        "                    result = result_map[pred]\n",
        "                    self.cache[(text1, text2)] = result\n",
        "                    batch_results.append(result)\n",
        "\n",
        "            # Insert batch results back into the right positions\n",
        "            for i, index in enumerate(uncached_indices):\n",
        "                results.insert(index, batch_results[i])\n",
        "\n",
        "            # Save cache after processing batch\n",
        "            if len(self.cache) % 100 == 0:\n",
        "                self._save_cache()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def check_implication(self, text1, text2, example=None):\n",
        "        \"\"\"Check entailment for a single pair (backward compatible).\"\"\"\n",
        "        cache_key = (text1, text2)\n",
        "        if cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        # Prepare input\n",
        "        inputs = self.tokenizer(\n",
        "            text1,\n",
        "            text2,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Move inputs to device\n",
        "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "\n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        # Map prediction\n",
        "        result_map = {0: 2, 1: 1, 2: 0}\n",
        "        result = result_map[predicted_class]\n",
        "\n",
        "        # Cache the result\n",
        "        self.cache[cache_key] = result\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulsao1Uw5jKm"
      },
      "source": [
        "# Clustering\n",
        "\n",
        "#also from their github got this\n",
        "\n",
        "```\n",
        "def get_semantic_ids(strings_list, model, strict_entailment=False, example=None):\n",
        "    \"\"\"Group list of predictions into semantic meaning.\"\"\"\n",
        "\n",
        "    def are_equivalent(text1, text2):\n",
        "\n",
        "        implication_1 = model.check_implication(text1, text2, example=example)\n",
        "        implication_2 = model.check_implication(text2, text1, example=example)  # pylint: disable=arguments-out-of-order\n",
        "        assert (implication_1 in [0, 1, 2]) and (implication_2 in [0, 1, 2])\n",
        "\n",
        "        if strict_entailment:\n",
        "            semantically_equivalent = (implication_1 == 2) and (implication_2 == 2)\n",
        "\n",
        "        else:\n",
        "            implications = [implication_1, implication_2]\n",
        "            # Check if none of the implications are 0 (contradiction) and not both of them are neutral.\n",
        "            semantically_equivalent = (0 not in implications) and ([1, 1] != implications)\n",
        "\n",
        "        return semantically_equivalent\n",
        "\n",
        "    # Initialise all ids with -1.\n",
        "    semantic_set_ids = [-1] * len(strings_list)\n",
        "    # Keep track of current id.\n",
        "    next_id = 0\n",
        "    for i, string1 in enumerate(strings_list):\n",
        "        # Check if string1 already has an id assigned.\n",
        "        if semantic_set_ids[i] == -1:\n",
        "            # If string1 has not been assigned an id, assign it next_id.\n",
        "            semantic_set_ids[i] = next_id\n",
        "            for j in range(i+1, len(strings_list)):\n",
        "                # Search through all remaining strings. If they are equivalent to string1, assign them the same id.\n",
        "                if are_equivalent(string1, strings_list[j]):\n",
        "                    semantic_set_ids[j] = next_id\n",
        "            next_id += 1\n",
        "\n",
        "    assert -1 not in semantic_set_ids\n",
        "\n",
        "    return semantic_set_ids\n",
        "\n",
        "\n",
        "def logsumexp_by_id(semantic_ids, log_likelihoods, agg='sum_normalized'):\n",
        "    \"\"\"Sum probabilities with the same semantic id.\n",
        "\n",
        "    Log-Sum-Exp because input and output probabilities in log space.\n",
        "    \"\"\"\n",
        "    unique_ids = sorted(list(set(semantic_ids)))\n",
        "    assert unique_ids == list(range(len(unique_ids)))\n",
        "    log_likelihood_per_semantic_id = []\n",
        "\n",
        "    for uid in unique_ids:\n",
        "        # Find positions in `semantic_ids` which belong to the active `uid`.\n",
        "        id_indices = [pos for pos, x in enumerate(semantic_ids) if x == uid]\n",
        "        # Gather log likelihoods at these indices.\n",
        "        id_log_likelihoods = [log_likelihoods[i] for i in id_indices]\n",
        "        if agg == 'sum_normalized':\n",
        "            # log_lik_norm = id_log_likelihoods - np.prod(log_likelihoods)\n",
        "            log_lik_norm = id_log_likelihoods - np.log(np.sum(np.exp(log_likelihoods)))\n",
        "            logsumexp_value = np.log(np.sum(np.exp(log_lik_norm)))\n",
        "        else:\n",
        "            raise ValueError\n",
        "        log_likelihood_per_semantic_id.append(logsumexp_value)\n",
        "\n",
        "    return log_likelihood_per_semantic_id\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NW3ag2a4LHhN"
      },
      "outputs": [],
      "source": [
        "def get_semantic_ids(strings_list, model, strict_entailment=False, example=None):\n",
        "\n",
        "    # Group list of predictions into semantic meaning\n",
        "\n",
        "    @lru_cache(maxsize=None)\n",
        "    def are_equivalent(text1, text2):\n",
        "        # Check if text1 entails text2\n",
        "        implication_1 = model.check_implication(text1, text2, example=example)\n",
        "        # Check if text2 entails text1\n",
        "        implication_2 = model.check_implication(text2, text1, example=example)\n",
        "        assert (implication_1 in [0, 1, 2]) and (implication_2 in [0, 1, 2])\n",
        "\n",
        "        if strict_entailment:\n",
        "            # Both must indicate entailment (2) for semantic equivalence\n",
        "            semantically_equivalent = (implication_1 == 2) and (implication_2 == 2)\n",
        "        else:\n",
        "            implications = [implication_1, implication_2]\n",
        "            # Check if none of the implications are 0 (contradiction) and not both of them are neutral.)\n",
        "            semantically_equivalent = (0 not in implications) and ([1, 1] != implications)\n",
        "\n",
        "        return semantically_equivalent\n",
        "\n",
        "    # Initialize all ids with -1\n",
        "    semantic_set_ids = [-1] * len(strings_list)\n",
        "    # Keep track of current id\n",
        "    next_id = 0\n",
        "\n",
        "    for i, string1 in enumerate(strings_list):\n",
        "        # Check if string1 already has an id assigned\n",
        "        if semantic_set_ids[i] == -1:\n",
        "            # If string1 has not been assigned an id, assign it next_id\n",
        "            semantic_set_ids[i] = next_id\n",
        "            for j in range(i+1, len(strings_list)):\n",
        "                # Search through all remaining strings. If they are equivalent to string1, assign them the same id.\n",
        "                if semantic_set_ids[j] == -1 and are_equivalent(string1, strings_list[j]):\n",
        "                    semantic_set_ids[j] = next_id\n",
        "            next_id += 1\n",
        "\n",
        "    assert -1 not in semantic_set_ids\n",
        "\n",
        "    return semantic_set_ids\n",
        "\n",
        "def logsumexp_by_id(semantic_ids, log_likelihoods, agg='sum_normalized'):\n",
        "    \"\"\"\n",
        "    Sum probabilities with the same semantic ID.\n",
        "    Log-Sum-Exp because input and output probabilities in log space.\n",
        "    \"\"\"\n",
        "    unique_ids = sorted(list(set(semantic_ids)))\n",
        "    assert unique_ids == list(range(len(unique_ids)))\n",
        "    log_likelihood_per_semantic_id = []\n",
        "\n",
        "    for uid in unique_ids:\n",
        "        # Find positions in `semantic_ids` which belong to the active `uid`\n",
        "        id_indices = [pos for pos, x in enumerate(semantic_ids) if x == uid]\n",
        "        # Gather log likelihoods at these indices\n",
        "        id_log_likelihoods = [log_likelihoods[i] for i in id_indices]\n",
        "\n",
        "        if agg == 'sum_normalized':\n",
        "            # Normalize by subtracting the log sum exp of all log likelihoods\n",
        "            # log_lik_norm = id_log_likelihoods - np.prod(log_likelihoods)\n",
        "            log_lik_norm = id_log_likelihoods - np.log(np.sum(np.exp(log_likelihoods)))\n",
        "            logsumexp_value = np.log(np.sum(np.exp(log_lik_norm)))\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown aggregation method: {agg}\")\n",
        "\n",
        "        log_likelihood_per_semantic_id.append(logsumexp_value)\n",
        "\n",
        "    return log_likelihood_per_semantic_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2wHskqM9lkQ"
      },
      "source": [
        "#entropy\n",
        "\n",
        "#from their github i got this code\n",
        "\n",
        "```\n",
        "\n",
        "def predictive_entropy(log_probs):\n",
        "    \"\"\"Compute MC estimate of entropy.\n",
        "\n",
        "    `E[-log p(x)] ~= -1/N sum_i log p(x_i)`, i.e. the average token likelihood.\n",
        "    \"\"\"\n",
        "\n",
        "    entropy = -np.sum(log_probs) / len(log_probs)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def predictive_entropy_rao(log_probs):\n",
        "    entropy = -np.sum(np.exp(log_probs) * log_probs)\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def cluster_assignment_entropy(semantic_ids):\n",
        "    \"\"\"Estimate semantic uncertainty from how often different clusters get assigned.\n",
        "\n",
        "    We estimate the categorical distribution over cluster assignments from the\n",
        "    semantic ids. The uncertainty is then given by the entropy of that\n",
        "    distribution. This estimate does not use token likelihoods, it relies soley\n",
        "    on the cluster assignments. If probability mass is spread of between many\n",
        "    clusters, entropy is larger. If probability mass is concentrated on a few\n",
        "    clusters, entropy is small.\n",
        "\n",
        "    Input:\n",
        "        semantic_ids: List of semantic ids, e.g. [0, 1, 2, 1].\n",
        "    Output:\n",
        "        cluster_entropy: Entropy, e.g. (-p log p).sum() for p = [1/4, 2/4, 1/4].\n",
        "    \"\"\"\n",
        "\n",
        "    n_generations = len(semantic_ids)\n",
        "    counts = np.bincount(semantic_ids)\n",
        "    probabilities = counts/n_generations\n",
        "    assert np.isclose(probabilities.sum(), 1)\n",
        "    entropy = - (probabilities * np.log(probabilities)).sum()\n",
        "    return entropy\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Euc93oDFGKCa"
      },
      "outputs": [],
      "source": [
        "def predictive_entropy_rao(log_probs):\n",
        "    \"\"\"\n",
        "    Compute entropy from log probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    - log_probs: Log probabilities\n",
        "\n",
        "    Returns:\n",
        "    - Entropy value\n",
        "    \"\"\"\n",
        "    entropy = -np.sum(np.exp(log_probs) * log_probs)\n",
        "    return entropy\n",
        "\n",
        "def predictive_entropy(log_probs):\n",
        "    \"\"\"Compute MC estimate of entropy.\n",
        "\n",
        "    `E[-log p(x)] ~= -1/N sum_i log p(x_i)`, i.e. the average token likelihood.\n",
        "    \"\"\"\n",
        "\n",
        "    entropy = -np.sum(log_probs) / len(log_probs)\n",
        "\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnKq6Ixs9iSr"
      },
      "source": [
        "# call function\n",
        "The actual full computation in the original repo happens in compute_uncertainty_measures.py:\n",
        " This  code is where they call the functions to compute the entropy measures\n",
        "\n",
        "```\n",
        "\n",
        "if args.compute_predictive_entropy:\n",
        "    # Token log likelihoods. Shape = (n_sample, n_tokens)\n",
        "    if not args.use_all_generations:\n",
        "        log_liks = [r[1] for r in full_responses[:args.use_num_generations]]\n",
        "    else:\n",
        "        log_liks = [r[1] for r in full_responses]\n",
        "\n",
        "    for i in log_liks:\n",
        "        assert i\n",
        "\n",
        "    if args.compute_context_entails_response:\n",
        "        # Compute context entails answer baseline.\n",
        "        entropies['context_entails_response'].append(context_entails_response(\n",
        "            context, responses, entailment_model))\n",
        "\n",
        "    if args.condition_on_question and args.entailment_model == 'deberta':\n",
        "        responses = [f'{question} {r}' for r in responses]\n",
        "\n",
        "    # Compute semantic ids.\n",
        "    semantic_ids = get_semantic_ids(\n",
        "        responses, model=entailment_model,\n",
        "        strict_entailment=args.strict_entailment, example=example)\n",
        "\n",
        "    result_dict['semantic_ids'].append(semantic_ids)\n",
        "\n",
        "    # Compute entropy from frequencies of cluster assignments.\n",
        "    entropies['cluster_assignment_entropy'].append(cluster_assignment_entropy(semantic_ids))\n",
        "\n",
        "    # Length normalization of generation probabilities.\n",
        "    log_liks_agg = [np.mean(log_lik) for log_lik in log_liks]\n",
        "\n",
        "    # Compute naive entropy.\n",
        "    entropies['regular_entropy'].append(predictive_entropy(log_liks_agg))\n",
        "\n",
        "    # Compute semantic entropy.\n",
        "    log_likelihood_per_semantic_id = logsumexp_by_id(semantic_ids, log_liks_agg, agg='sum_normalized')\n",
        "    pe = predictive_entropy_rao(log_likelihood_per_semantic_id)\n",
        "    entropies['semantic_entropy'].append(pe)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_uy0aCxkIL_R"
      },
      "outputs": [],
      "source": [
        "def experiment_semantic_entropy(question, original_answer ,llm_model, llm_tokenizer, entailment_model, num_samples):\n",
        "    \"\"\"\n",
        "    Compute semantic entropy for a given question.\n",
        "    Returns:\n",
        "        Dictionary containing results of the experiment\n",
        "    \"\"\"\n",
        "    # Step 1: Generate multiple answers with their token log likelihoods\n",
        "    #print(f\"Generating {num_samples} answers for question: {question}\")\n",
        "    results = generate_answer(question, num_samples, llm_model, llm_tokenizer)\n",
        "\n",
        "    # Step 2: Extract answers and their log likelihoods\n",
        "    answers = [result['text'] for result in results]\n",
        "    # length normalization of the log probabilities\n",
        "    log_likelihoods = [np.mean(result['token_log_probs']) for result in results]\n",
        "\n",
        "   # print(f\"Generated {len(answers)} answers\")\n",
        "\n",
        "    # Step 3: Create an example dictionary for entailment checking\n",
        "    example = {'question': question}\n",
        "\n",
        "    # Step 4: Compute semantic clusters\n",
        "   # print(\"Computing semantic clusters...\")\n",
        "    semantic_ids = get_semantic_ids(answers, entailment_model, strict_entailment=False, example=example)\n",
        "    unique_clusters = len(set(semantic_ids))\n",
        "   # print(f\"Found {unique_clusters} semantic clusters\")\n",
        "\n",
        "    # Step 5: Calculate entropy measures\n",
        "    # naive_entropy calculation (based on log likelihoods only)\n",
        "    naive_entropy = predictive_entropy(log_likelihoods)\n",
        "\n",
        "    # Semantic entropy calculation (based on semantic clusters and log likelihoods)\n",
        "    log_likelihood_per_semantic_id = logsumexp_by_id(semantic_ids, log_likelihoods, agg='sum_normalized')\n",
        "    semantic_entropy = predictive_entropy_rao(log_likelihood_per_semantic_id)\n",
        "\n",
        "    # Step 6: Print results\n",
        "    print(f\"\\nEntropy Analysis for: '{question}'\")\n",
        "    print(f\"Generated {len(answers)} answers in {unique_clusters} semantic clusters\")\n",
        "    #print the entropy values with 4 decimal places\n",
        "    print(f\" naive Entropy: {naive_entropy:.4f}\")\n",
        "    print(f\"Semantic Entropy: {semantic_entropy:.4f}\")\n",
        "\n",
        "\n",
        "    # Step 7: Display cluster information\n",
        "    #print(\"\\nSemantic Clusters:\")\n",
        "    unique_clusters_list = sorted(list(set(semantic_ids)))\n",
        "    for cluster_id in unique_clusters_list:\n",
        "        cluster_items = [answers[i] for i, sid in enumerate(semantic_ids) if sid == cluster_id]\n",
        "        count = len(cluster_items)\n",
        "        '''\n",
        "        print(f\"\\nCluster {cluster_id} ({count} items):\")\n",
        "        for item in cluster_items:\n",
        "            print(f\"  - {item}\")\n",
        "        '''\n",
        "    # Format answers in the  structure\n",
        "    formatted_answers = []\n",
        "    for cluster_id in unique_clusters_list:\n",
        "        cluster_answers = [answers[i] for i, sid in enumerate(semantic_ids) if sid == cluster_id]\n",
        "        formatted_answers.append(cluster_answers)\n",
        "\n",
        "    # Return  results\n",
        "    # number like 2.220446049250313e-16 is extremely close to zero (basically floating-point noise).\n",
        "    # so rounds the number to 4 decimal places\n",
        "  # Return results with details and formatted answers\n",
        "    return {\n",
        "        'question': question,\n",
        "        'original_answer': original_answer,  # Include the original answer from the dataset\n",
        "        'answers': formatted_answers,  # Answers formatted\n",
        "        'log_likelihoods': log_likelihoods,\n",
        "        'semantic_ids': semantic_ids,\n",
        "        'naive_entropy': round(naive_entropy, 4),\n",
        "        'semantic_entropy': round(semantic_entropy, 4),\n",
        "        'num_clusters': unique_clusters,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0EoVG07fDNN"
      },
      "source": [
        "#get likelihood\n",
        "\n",
        "#from their code\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "#at this function\n",
        "def predict(self, input_data, temperature, return_full=False):\n",
        "\n",
        "\n",
        "        # Get log_likelihoods.\n",
        "        # outputs.scores are the logits for the generated token.\n",
        "        # outputs.scores is a tuple of len = n_generated_tokens.\n",
        "        # Each entry is shape (bs, vocabulary size).\n",
        "        # outputs.sequences is the sequence of all tokens: input and generated.\n",
        "        transition_scores = self.model.compute_transition_scores(\n",
        "            outputs.sequences, outputs.scores, normalize_logits=True)\n",
        "        # Transition_scores[0] only contains the scores for the first generated tokens.\n",
        "\n",
        "        log_likelihoods = [score.item() for score in transition_scores[0]]\n",
        "        if len(log_likelihoods) == 1:\n",
        "            logging.warning('Taking first and only generation for log likelihood!')\n",
        "            log_likelihoods = log_likelihoods\n",
        "        else:\n",
        "            log_likelihoods = log_likelihoods[:n_generated]\n",
        "\n",
        "        if len(log_likelihoods) == self.max_new_tokens:\n",
        "            logging.warning('Generation interrupted by max_token limit.')\n",
        "\n",
        "        if len(log_likelihoods) == 0:\n",
        "            raise ValueError\n",
        "\n",
        "        return sliced_answer, log_likelihoods, last_token_embedding\n",
        "\n",
        "\n",
        "all function if needed\n",
        "f predict(self, input_data, temperature, return_full=False):\n",
        "\n",
        "        # Implement prediction.\n",
        "        inputs = self.tokenizer(input_data, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        if 'llama' in self.model_name.lower() or 'falcon' in self.model_name or 'mistral' in self.model_name.lower():\n",
        "            if 'token_type_ids' in inputs:  # Some HF models have changed.\n",
        "                del inputs['token_type_ids']\n",
        "            pad_token_id = self.tokenizer.eos_token_id\n",
        "        else:\n",
        "            pad_token_id = None\n",
        "\n",
        "        if self.stop_sequences is not None:\n",
        "            stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(\n",
        "                stops=self.stop_sequences,\n",
        "                initial_length=len(inputs['input_ids'][0]),\n",
        "                tokenizer=self.tokenizer)])\n",
        "        else:\n",
        "            stopping_criteria = None\n",
        "\n",
        "        logging.debug('temperature: %f', temperature)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=self.max_new_tokens,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "                output_hidden_states=True,\n",
        "                temperature=temperature,\n",
        "                do_sample=True,\n",
        "                stopping_criteria=stopping_criteria,\n",
        "                pad_token_id=pad_token_id,\n",
        "            )\n",
        "\n",
        "        if len(outputs.sequences[0]) > self.token_limit:\n",
        "            raise ValueError(\n",
        "                'Generation exceeding token limit %d > %d',\n",
        "                len(outputs.sequences[0]), self.token_limit)\n",
        "\n",
        "        full_answer = self.tokenizer.decode(\n",
        "            outputs.sequences[0], skip_special_tokens=True)\n",
        "\n",
        "        if return_full:\n",
        "            return full_answer\n",
        "\n",
        "        # For some models, we need to remove the input_data from the answer.\n",
        "        if full_answer.startswith(input_data):\n",
        "            input_data_offset = len(input_data)\n",
        "        else:\n",
        "            raise ValueError('Have not tested this in a while.')\n",
        "\n",
        "        # Remove input from answer.\n",
        "        answer = full_answer[input_data_offset:]\n",
        "\n",
        "        # Remove stop_words from answer.\n",
        "        stop_at = len(answer)\n",
        "        sliced_answer = answer\n",
        "        if self.stop_sequences is not None:\n",
        "            for stop in self.stop_sequences:\n",
        "                if answer.endswith(stop):\n",
        "                    stop_at = len(answer) - len(stop)\n",
        "                    sliced_answer = answer[:stop_at]\n",
        "                    break\n",
        "            if not all([stop not in sliced_answer for stop in self.stop_sequences]):\n",
        "                error_msg = 'Error: Stop words not removed successfully!'\n",
        "                error_msg += f'Answer: >{answer}< '\n",
        "                error_msg += f'Sliced Answer: >{sliced_answer}<'\n",
        "                if 'falcon' not in self.model_name.lower():\n",
        "                    raise ValueError(error_msg)\n",
        "                else:\n",
        "                    logging.error(error_msg)\n",
        "\n",
        "        # Remove whitespaces from answer (in particular from beginning.)\n",
        "        sliced_answer = sliced_answer.strip()\n",
        "\n",
        "        # Get the number of tokens until the stop word comes up.\n",
        "        # Note: Indexing with `stop_at` already excludes the stop_token.\n",
        "        # Note: It's important we do this with full answer, since there might be\n",
        "        # non-trivial interactions between the input_data and generated part\n",
        "        # in tokenization (particularly around whitespaces.)\n",
        "        token_stop_index = self.tokenizer(full_answer[:input_data_offset + stop_at], return_tensors=\"pt\")['input_ids'].shape[1]\n",
        "        n_input_token = len(inputs['input_ids'][0])\n",
        "        n_generated = token_stop_index - n_input_token\n",
        "\n",
        "        if n_generated == 0:\n",
        "            logging.warning('Only stop_words were generated. For likelihoods and embeddings, taking stop word instead.')\n",
        "            n_generated = 1\n",
        "\n",
        "        # Get the last hidden state (last layer) and the last token's embedding of the answer.\n",
        "        # Note: We do not want this to be the stop token.\n",
        "\n",
        "        # outputs.hidden_state is a tuple of len = n_generated_tokens.\n",
        "        # The first hidden state is for the input tokens and is of shape\n",
        "        #     (n_layers) x (batch_size, input_size, hidden_size).\n",
        "        # (Note this includes the first generated token!)\n",
        "        # The remaining hidden states are for the remaining generated tokens and is of shape\n",
        "        #    (n_layers) x (batch_size, 1, hidden_size).\n",
        "\n",
        "        # Note: The output embeddings have the shape (batch_size, generated_length, hidden_size).\n",
        "        # We do not get embeddings for input_data! We thus subtract the n_tokens_in_input from\n",
        "        # token_stop_index to arrive at the right output.\n",
        "\n",
        "        if 'decoder_hidden_states' in outputs.keys():\n",
        "            hidden = outputs.decoder_hidden_states\n",
        "        else:\n",
        "            hidden = outputs.hidden_states\n",
        "\n",
        "        if len(hidden) == 1:\n",
        "            logging.warning(\n",
        "                'Taking first and only generation for hidden! '\n",
        "                'n_generated: %d, n_input_token: %d, token_stop_index %d, '\n",
        "                'last_token: %s, generation was: %s',\n",
        "                n_generated, n_input_token, token_stop_index,\n",
        "                self.tokenizer.decode(outputs['sequences'][0][-1]),\n",
        "                full_answer,\n",
        "                )\n",
        "            last_input = hidden[0]\n",
        "        elif ((n_generated - 1) >= len(hidden)):\n",
        "            # If access idx is larger/equal.\n",
        "            logging.error(\n",
        "                'Taking last state because n_generated is too large'\n",
        "                'n_generated: %d, n_input_token: %d, token_stop_index %d, '\n",
        "                'last_token: %s, generation was: %s, slice_answer: %s',\n",
        "                n_generated, n_input_token, token_stop_index,\n",
        "                self.tokenizer.decode(outputs['sequences'][0][-1]),\n",
        "                full_answer, sliced_answer\n",
        "                )\n",
        "            last_input = hidden[-1]\n",
        "        else:\n",
        "            last_input = hidden[n_generated - 1]\n",
        "\n",
        "        # Then access last layer for input\n",
        "        last_layer = last_input[-1]\n",
        "        # Then access last token in input.\n",
        "        last_token_embedding = last_layer[:, -1, :].cpu()\n",
        "\n",
        "        # Get log_likelihoods.\n",
        "        # outputs.scores are the logits for the generated token.\n",
        "        # outputs.scores is a tuple of len = n_generated_tokens.\n",
        "        # Each entry is shape (bs, vocabulary size).\n",
        "        # outputs.sequences is the sequence of all tokens: input and generated.\n",
        "        transition_scores = self.model.compute_transition_scores(\n",
        "            outputs.sequences, outputs.scores, normalize_logits=True)\n",
        "        # Transition_scores[0] only contains the scores for the first generated tokens.\n",
        "\n",
        "        log_likelihoods = [score.item() for score in transition_scores[0]]\n",
        "        if len(log_likelihoods) == 1:\n",
        "            logging.warning('Taking first and only generation for log likelihood!')\n",
        "            log_likelihoods = log_likelihoods\n",
        "        else:\n",
        "            log_likelihoods = log_likelihoods[:n_generated]\n",
        "\n",
        "        if len(log_likelihoods) == self.max_new_tokens:\n",
        "            logging.warning('Generation interrupted by max_token limit.')\n",
        "\n",
        "        if len(log_likelihoods) == 0:\n",
        "            raise ValueError\n",
        "\n",
        "        return sliced_answer, log_likelihoods, last_token_embedding\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFYlG7k_gCIS"
      },
      "source": [
        "##log probabilities vs negative log likelihoods:\n",
        "\n",
        "- Log probabilities are the logarithm of the probability: log(p)\n",
        "- Negative log likelihoods are the negative logarithm of the probability: -log(p)\n",
        "\n",
        "The original code is working with log probabilities, not negative log likelihoods. We see normalize_logits=True in compute_transition_scores, it means the model is returning log probabilities.\n",
        "\n",
        "\n",
        "**The original code is using predictive_entropy_rao, which expects log probabilities as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JXUkp0AdvHBb"
      },
      "outputs": [],
      "source": [
        "def generate_answer(question, num_samples, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generate multiple answers to a question using LLM with direct token log likelihoods.\n",
        "    \"\"\"\n",
        "    # Create the prompt with the question\n",
        "    prompt = f\"أجب على السؤال التالي بجملة واحدة فقط موجزة ولكن كاملة باللغة العربية\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Tokenize the prompt\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        prompt_length = inputs.input_ids.shape[1]  # Number of tokens in the prompt\n",
        "\n",
        "        # Generate with return_dict_in_generate=True and output_scores=True to get scores\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_new_tokens=100,\n",
        "                do_sample=True,\n",
        "                temperature=0.5,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "            )\n",
        "\n",
        "        # Calculate token log probabilities using compute_transition_scores\n",
        "        # normalize_logits=True ensures we get log probabilities\n",
        "        transition_scores = model.compute_transition_scores(\n",
        "            outputs.sequences,\n",
        "            outputs.scores,\n",
        "            normalize_logits=True\n",
        "        )\n",
        "\n",
        "        # Extract log likelihoods like they did exactly, but no handeling of cases\n",
        "        log_likelihoods = [score.item() for score in transition_scores[0]]\n",
        "\n",
        "\n",
        "        # Decode the generated text\n",
        "        generated_text = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
        "        answer = generated_text.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "        # Clean the output\n",
        "        strings_to_filter_on = ['.', '\\n', 'Q:', 'A:', 'question:', 'answer:', 'Question:', 'Answer:',\n",
        "                               'Questions:', 'questions:', 'QUESTION:', 'ANSWER:']\n",
        "        for string in strings_to_filter_on:\n",
        "            if string in answer:\n",
        "                answer = answer.split(string)[0].strip()\n",
        "\n",
        "        results.append({\n",
        "            'text': answer,\n",
        "            'token_log_probs': log_likelihoods,  # Store raw log probabilities\n",
        "\n",
        "        })\n",
        "\n",
        "    return results # Return results AFTER the loop completes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKCz4R7jnK7D"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a8ag496J_opE"
      },
      "outputs": [],
      "source": [
        "def load_qa_dataset(dataset_name, file_path=None):\n",
        "    data = []\n",
        "\n",
        "    try:\n",
        "        if dataset_name == 'arabicaqa' and file_path:\n",
        "            if os.path.exists(file_path):  # Use the loaded file\n",
        "                print(\"Using ArabicaQA\")\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    custom_data = json.load(f)\n",
        "                    for idx, item in enumerate(custom_data):\n",
        "                        data.append({\n",
        "                            \"question_id\": idx,\n",
        "                            \"Question\": item[\"question\"],\n",
        "                            \"Answer\": item[\"answer\"]\n",
        "                        })\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"ArabicaQA file not found at {file_path}\")\n",
        "\n",
        "        elif dataset_name == 'xor_tydiqa' and file_path:\n",
        "            if os.path.exists(file_path):  # Use the loaded file\n",
        "                print(\"Using XOR-TyDiQA\")\n",
        "                print(\"Filtering Arabic QA pairs from XOR-TyDi...\")\n",
        "\n",
        "                # Load the jsonl dataset\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    custom_data = [json.loads(line) for line in f]  # Handling jsonl\n",
        "\n",
        "                # Filter Arabic samples (\"lang\" = \"ar\")\n",
        "                arabic_data = []\n",
        "                for idx, item in enumerate(custom_data):\n",
        "                    if item[\"lang\"] == \"ar\":  # Arabic language code\n",
        "                        arabic_data.append({\n",
        "                            \"question_id\": item[\"id\"],\n",
        "                            \"Question\": item[\"question\"],\n",
        "                            \"Answer\": item[\"answers\"][0]  # First answer in list\n",
        "                        })\n",
        "\n",
        "                data.extend(arabic_data)\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"XOR-TyDiQA file not found at {file_path}\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {dataset_name}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B6fdiUCITVs"
      },
      "outputs": [],
      "source": [
        "# Function to safely load existing partial results\n",
        "def load_partial_results(partial_file_path):\n",
        "    if os.path.exists(partial_file_path):\n",
        "        with open(partial_file_path, 'r', encoding='utf-8') as f:\n",
        "            saved_results = json.load(f)\n",
        "        print(f\"✓ Loaded {len(saved_results)} saved results from checkpoint.\")\n",
        "        return saved_results\n",
        "    else:\n",
        "        print(\"✓ No previous checkpoint found. Starting fresh.\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_CHOICE = \"jais\"  # Options: \"llama\", \"allam\", \"jais\", \"qwen\"\n",
        "    START_FROM_QUESTION = 2202\n",
        "\n",
        "    print(\"Loading language model...\")\n",
        "\n",
        "    if MODEL_CHOICE == \"llama\":\n",
        "        model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        print(f\"Loaded Llama 3.1 model successfully\")\n",
        "\n",
        "    elif MODEL_CHOICE == \"allam\":\n",
        "        model_id = \"ALLaM-AI/ALLaM-7B-Instruct-preview\"\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        print(f\"Loaded ALLaM model successfully\")\n",
        "\n",
        "    elif MODEL_CHOICE == \"jais\":\n",
        "        model_id = \"inceptionai/jais-family-6p7b-chat\"\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        print(f\"Loaded Jais model successfully\")\n",
        "\n",
        "    elif MODEL_CHOICE == \"qwen\":\n",
        "        model_id = \"Qwen/Qwen2-7B-Instruct\"\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        print(f\"Loaded Qwen2 model successfully\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model choice: {MODEL_CHOICE}\")\n",
        "\n",
        "    print(\"Loading entailment model...\")\n",
        "    entailment_model = ArabicEntailmentModel()\n",
        "    print(\"Entailment model loaded successfully\")\n",
        "\n",
        "    print(\"Loading dataset...\")\n",
        "    DATASET_CHOICE = 'arabicaqa'  # Options: 'arabicaqa', 'xor_tydiqa'\n",
        "    FILE_PATH = '/content/test-open.json'\n",
        "    data = load_qa_dataset(DATASET_CHOICE, FILE_PATH)\n",
        "    print(f\"Loaded {len(data)} questions from {DATASET_CHOICE}\")\n",
        "\n",
        "    print(\"\\nStarting semantic entropy experiments...\")\n",
        "\n",
        "    partial_save_path = f'semantic_entropy_{MODEL_CHOICE}_partial_results.json'\n",
        "\n",
        "    # Load previous partial results if available\n",
        "    results = load_partial_results(partial_save_path)\n",
        "\n",
        "    #  starting point\n",
        "    if START_FROM_QUESTION is not None:\n",
        "\n",
        "        already_processed = START_FROM_QUESTION\n",
        "        # Trim results to match the starting point if needed\n",
        "        if len(results) > already_processed:\n",
        "            results = results[:already_processed]\n",
        "            print(f\"Truncated results to match starting point at question {already_processed}\")\n",
        "    else:\n",
        "        # Use checkpoint\n",
        "        already_processed = len(results)\n",
        "\n",
        "    print(f\"Starting from question {already_processed + 1}\")\n",
        "\n",
        "    MAX_QUESTIONS = 6000  # the last question in a run\n",
        "    test_questions = data[:MAX_QUESTIONS] if MAX_QUESTIONS else data\n",
        "\n",
        "    for i, item in tqdm(enumerate(test_questions[already_processed:], start=already_processed),\n",
        "                         total=len(test_questions)-already_processed,\n",
        "                         desc=\"Processing questions\"):\n",
        "        question = item[\"Question\"]\n",
        "        original_answer = item[\"Answer\"]\n",
        "        print(f\"\\n[{i+1}/{len(test_questions)}] Processing question\")\n",
        "\n",
        "        result = experiment_semantic_entropy(\n",
        "            question=question,\n",
        "            original_answer=original_answer,\n",
        "            llm_model=llm_model,\n",
        "            llm_tokenizer=llm_tokenizer,\n",
        "            entailment_model=entailment_model,\n",
        "            num_samples=10\n",
        "        )\n",
        "        results.append(result)\n",
        "\n",
        "        # Save progress after every 5 questions\n",
        "        if (i+1) % 5 == 0:\n",
        "            with open(partial_save_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"✓ Saved partial progress after {i+1} questions.\")\n",
        "\n",
        "    # Save final results\n",
        "    final_save_path = f'semantic_entropy_{MODEL_CHOICE}_{DATASET_CHOICE}_resultsP2.json'\n",
        "    print(\"\\nSaving final results...\")\n",
        "    with open(final_save_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "    files.download(final_save_path)\n",
        "    print(f\"✓ Experiment completed successfully with {MODEL_CHOICE} model!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to safely load existing partial results\n",
        "def load_partial_results(partial_file_path):\n",
        "    if os.path.exists(partial_file_path):\n",
        "        with open(partial_file_path, 'r', encoding='utf-8') as f:\n",
        "            saved_results = json.load(f)\n",
        "        print(f\"✓ Loaded {len(saved_results)} saved results from checkpoint.\")\n",
        "        return saved_results\n",
        "    else:\n",
        "        print(\"✓ No previous checkpoint found. Starting fresh.\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_CHOICE = \"jais\"  # Options: \"llama\", \"allam\", \"jais\", \"qwen\"\n",
        "\n",
        "    print(\"Loading language model...\")\n",
        "    if MODEL_CHOICE == \"llama\":\n",
        "        model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        print(f\"Loaded Llama 3.1 model successfully\")\n",
        "\n",
        "    elif MODEL_CHOICE == \"allam\":\n",
        "        model_id = \"ALLaM-AI/ALLaM-7B-Instruct-preview\"\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        print(f\"Loaded ALLaM model successfully\")\n",
        "\n",
        "    elif MODEL_CHOICE == \"jais\":\n",
        "        model_id = \"inceptionai/jais-family-6p7b-chat\"\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        print(f\"Loaded Jais model successfully\")\n",
        "\n",
        "    elif MODEL_CHOICE == \"qwen\":\n",
        "        model_id = \"Qwen/Qwen2-7B-Instruct\"\n",
        "        llm_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        print(f\"Loaded Qwen2 model successfully\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model choice: {MODEL_CHOICE}\")\n",
        "\n",
        "    print(\"Loading entailment model...\")\n",
        "    entailment_model = ArabicEntailmentModel()\n",
        "    print(\"Entailment model loaded successfully\")\n",
        "\n",
        "    print(\"Loading dataset...\")\n",
        "    DATASET_CHOICE = 'arabicaqa'  # Options: 'arabicaqa', 'xor_tydiqa'\n",
        "    FILE_PATH = '/content/test-open.json'\n",
        "    data = load_qa_dataset(DATASET_CHOICE, FILE_PATH)\n",
        "    print(f\"Loaded {len(data)} questions from {DATASET_CHOICE}\")\n",
        "\n",
        "    print(\"\\nStarting semantic entropy experiments...\")\n",
        "    partial_save_path = f'semantic_entropy_{MODEL_CHOICE}_partial_results.json'\n",
        "\n",
        "    # Load previous partial results if available\n",
        "    results = load_partial_results(partial_save_path)\n",
        "\n",
        "    already_processed = len(results)\n",
        "    print(f\"Starting from question {already_processed + 1}\")\n",
        "\n",
        "    MAX_QUESTIONS = 6000  # Set to a number or None\n",
        "    test_questions = data[:MAX_QUESTIONS] if MAX_QUESTIONS else data\n",
        "\n",
        "    for i, item in tqdm(enumerate(test_questions[already_processed:], start=already_processed),\n",
        "                         total=len(test_questions)-already_processed,\n",
        "                         desc=\"Processing questions\"):\n",
        "        question = item[\"Question\"]\n",
        "        original_answer = item[\"Answer\"]\n",
        "        print(f\"\\n[{i+1}/{len(test_questions)}] Processing question\")\n",
        "\n",
        "        result = experiment_semantic_entropy(\n",
        "            question=question,\n",
        "            original_answer=original_answer,\n",
        "            llm_model=llm_model,\n",
        "            llm_tokenizer=llm_tokenizer,\n",
        "            entailment_model=entailment_model,\n",
        "            num_samples=10\n",
        "        )\n",
        "        results.append(result)\n",
        "\n",
        "        # Save progress after every 5 questions\n",
        "        if (i+1) % 5 == 0:\n",
        "            with open(partial_save_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"✓ Saved partial progress after {i+1} questions.\")\n",
        "\n",
        "    # Save final results\n",
        "    final_save_path = f'semantic_entropy_{MODEL_CHOICE}_{DATASET_CHOICE}_results.json'\n",
        "    print(\"\\nSaving final results...\")\n",
        "    with open(final_save_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "    files.download(final_save_path)\n",
        "    print(f\"✓ Experiment completed successfully with {MODEL_CHOICE} model!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce2418df4aef43239f305453d71546eb",
            "6be7faeff02142a6bc3c1224ebd587bc",
            "0d471c85c1574e18a45a6d2496c12473",
            "d01df6d0899d428e9b12085ffa2f5889",
            "d31b67cc11f04738a122b455f368ff5c",
            "5e4405a5d32147bc8d8445e3927354dd",
            "fd2e427c50164cddafb0fb5e33231d91",
            "1da1a29e69dd41b58ed30b082cb42601",
            "cf89feb992bc43bc9d7a9744f0535f33",
            "97e2406fd59b4821bb7ee13d9c4cad27",
            "09c2ec0d0d37471db574584234d57c6d",
            "8563b07aaa4841509a38552a92637d41",
            "bef4437379304b3ba100080f13fc4431",
            "31caeb126831429d98be47cc297291d3",
            "f9fff8abe4fe4272bbf9e3577bbecd2f",
            "449c30770148419a9767dba429ca3802",
            "fc5972fae8fa41ec933b35554163bd89",
            "f01f5ec1fe0048d7bdd4a9184cc04f35",
            "dca60a3415da404b9078bd00abd19fe3",
            "afc4189b1e19478fb797287ce4bedada",
            "3c295a76dda74ecfb029399846a4b1e0",
            "223fca8cb9b44b55babb67c1e60c086d",
            "b3bec33e82134b34b31e7b9c110701eb",
            "a0d6d82ba9174cc6b29b03687f071edc",
            "e308e7cb52224688a4d33b7a53a049bf",
            "439ee4b7a6ae44d88b24daf67d156faf",
            "3e74ee04472f4580b1246de33796e76d",
            "d519c15ba3e44d4c9ff2f21acb1f629f",
            "85dee41c27674c5e91652806212a38c6",
            "5192eeb6b7074132916e18319ba7c2a7",
            "570064ae5ca84241bb3fcd92150ea75e",
            "c673d0ee7450434b9983de27e2d611ad",
            "3b8c5c2914994231973c9b29d8ed0486",
            "e03014afbb774ef4b242edc2fe1ea67e",
            "0c8c5c7e77664367ad9740eae294c4b5",
            "0b050627c9f04df3b8f358599da87a41",
            "4bdbc7a403ab4218bc83d6c81425e660",
            "fa89d388e9994021a37020d3a7daed84",
            "01e8ddc8d73e4f09a8e2f4409ebb2416",
            "5b7610131c0a4d899222b9ff0874c273",
            "5ebb874d69c94a648b7d8309f4742d3a",
            "55952d679fa34d2d978207bb7588d990",
            "e97a552034f340e1a533ef2b7e1c2edd",
            "f4f1e6d4b2404a57bc62461c353dd241",
            "a635c53a78fc4c1da81c5e59108ad171",
            "f667efc38b354407988dae37228d638c",
            "0fcb10c29b6247eb9c494822e06dcaa2",
            "e777c8be9cdc446795583f4618ce2cd4",
            "18dba330a0fc485a889e8daecd36cf04",
            "4a6d046a6a654b23b35816500b3296ab",
            "d57931384d98452bbc059fe760cfef5e",
            "3dd916ff4bec41539693a412f4557aee",
            "34dff7e43ca54fd3938249ebe11cc864",
            "4fcbe0c3063848418aa0e53318433f32",
            "d922b0d525054dc3af0154e31e27b853",
            "7c4d083597894df79c6fff117e451dbf",
            "cc1a5383d5674bff8199d56721370f8c",
            "a1908a7656544da48d95c0a62eae84f8",
            "30a981a23b3f441986ef1e2930acda86",
            "441f7b80c67f47f292d15e05262b2f84",
            "05cf6bc142644e4aa6c6628de4298184",
            "659b4048b198459fa94c2a426561e17e",
            "39ce9d4906684022b461a24134739d56",
            "24569e6bdb26462d8c494023132b1005",
            "4315262cffe54e979021755e1c89058a",
            "ec0e8c40f9d946f8a95c3f088f75cffc",
            "8e9786c4040a4c91b210cbace1813e39",
            "f0fec91aec2f4d5786553c084e445c00",
            "b2ff0c55b7c14e4b84570794102eab94",
            "19af40b6718b425192004a274d0d77d1",
            "385531e8cdb948eead5752e9d14a22a1",
            "70b6b07f3cd74a69a38def26609d8c33",
            "d19ab7bcd08e403489facdf3360f3a72",
            "ef38aaf37c5a4abcbc51aa83e6c6d471",
            "0ea40197da814e3e8a9fac3a6bad0620",
            "06a28799014243f08d72589de0394eea",
            "f16efbe3948a40ebaf20df1fdba5b5b9",
            "78230125567649e3ad827c9e60a2362a",
            "314dde10390b4983938a23886d67e19d",
            "0d648dde3f6f47fd8ce9ad2693b8efca",
            "46cfae177e2a429798e7545bc33f2139",
            "dcb116e807c7403daaf25ae49a1ac316",
            "193a46b30c494b08ba38d5e718d6b6ec",
            "ea584059c88a4e8b9d4d034e21edb26d",
            "830347169df846d0a3d1e93fb38d8222",
            "42cce5b58d8948b79cf009a3186761fa",
            "ab17077251354dbebb3515ec838edddb",
            "d34ec4364afb4fbea829b0bfd5b28db7",
            "5989ced8b3cf446b9df3b4612d4cd701",
            "328f97e11dfe4546b91dd7b6d6ac54b6",
            "0d9ff5d09faa4ca4bbe82c07c7d73a8c",
            "d111dfcdc2c2433b8951df35d77aa4c7",
            "ceefda54887844c88bb8ab1b13efdd88",
            "9b2361ce93814f24bda10c47999e5505",
            "1860f0baa5d14accabc32b9d19def362",
            "54b66221fa354fcfba4a8aaaa26c1328",
            "ac5bc92293814d69838aea97d61c45e3",
            "2b1bba38154947f59bb34d165efba234",
            "71327088a77c44c6b98c4d84094b4b6f"
          ]
        },
        "id": "7kc_fQg8hzjI",
        "outputId": "73a50390-bb11-46d5-ff48-c8c1cb2f134b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading language model...\n",
            "The repository for inceptionai/jais-family-6p7b-chat contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/inceptionai/jais-family-6p7b-chat.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] Y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_jais.py:   0%|          | 0.00/9.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce2418df4aef43239f305453d71546eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/inceptionai/jais-family-6p7b-chat:\n",
            "- configuration_jais.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for inceptionai/jais-family-6p7b-chat contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/inceptionai/jais-family-6p7b-chat.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] Y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_jais.py:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8563b07aaa4841509a38552a92637d41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/inceptionai/jais-family-6p7b-chat:\n",
            "- modeling_jais.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/35.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3bec33e82134b34b31e7b9c110701eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e03014afbb774ef4b242edc2fe1ea67e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/9.85G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a635c53a78fc4c1da81c5e59108ad171"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/8.82G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c4d083597894df79c6fff117e451dbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e9786c4040a4c91b210cbace1813e39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78230125567649e3ad827c9e60a2362a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Jais model successfully\n",
            "Loading entailment model...\n",
            "Loading AraELECTRA model for Arabic entailment checking...\n",
            "AraELECTRA model loaded successfully\n",
            "Entailment model loaded successfully\n",
            "Loading dataset...\n",
            "Using ArabicaQA\n",
            "Loaded 12592 questions from arabicaqa\n",
            "\n",
            "Starting semantic entropy experiments...\n",
            "✓ No previous checkpoint found. Starting fresh.\n",
            "Starting from question 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing questions:   0%|          | 0/6000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5989ced8b3cf446b9df3b4612d4cd701"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Semantic Entropy: 1.0626\n",
            "\n",
            "[5368/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى يتم إغلاق الدرز بين العظام في الجمجمة؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2722\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5369/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الطرق التي استخدمت في المجتمعات القديمة لتغيير شكل الرأس؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6398\n",
            "Semantic Entropy: 1.2649\n",
            "\n",
            "[5370/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يختلف القبو القحفي في البرمائيات والزواحف عن تلك في الثدييات والطيور؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2573\n",
            "Semantic Entropy: 0.6294\n",
            "✓ Saved partial progress after 5370 questions.\n",
            "\n",
            "[5371/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور مدينة هافانا في كوبا؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2651\n",
            "Semantic Entropy: 0.6520\n",
            "\n",
            "[5372/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الموانئ الرئيسية في هافانا؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1601\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5373/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف أصبحت هافانا رأس المال الحقيقية لكوبا؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4395\n",
            "Semantic Entropy: 1.5678\n",
            "\n",
            "[5374/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية التحصينات في ميناء هافانا ودورها في التاريخ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5254\n",
            "Semantic Entropy: 1.7313\n",
            "\n",
            "[5375/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '\n",
            "من الذي قام بأول زيارة من قبل الأوروبيين للجزيرة؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.2988\n",
            "Semantic Entropy: 1.4190\n",
            "✓ Saved partial progress after 5375 questions.\n",
            "\n",
            "[5376/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من أسس مدينة هافانا ؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2384\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5377/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم تاسيس هافانا'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3361\n",
            "Semantic Entropy: 1.1366\n",
            "\n",
            "[5378/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الهجمات التي تعرضت لها هافانا من القراصنة والبحرية الفرنسية؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4778\n",
            "Semantic Entropy: 1.9941\n",
            "\n",
            "[5379/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي السلع التي تم تداولها في هافانا؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3541\n",
            "Semantic Entropy: 0.9873\n",
            "\n",
            "[5380/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تعداد سكان هافانا في منتصف القرن الثامن عشر؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3096\n",
            "Semantic Entropy: 1.2715\n",
            "✓ Saved partial progress after 5380 questions.\n",
            "\n",
            "[5381/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو البناء الديني الذي تم بناؤه في هافانا خلال هذه الفترة؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4690\n",
            "Semantic Entropy: 1.7712\n",
            "\n",
            "[5382/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المركز الذي يلعب فيه جون هنتلي في فريق كرة القدم؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.1576\n",
            "Semantic Entropy: 1.1142\n",
            "\n",
            "[5383/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي تاريخ وُلد جون هنتلي؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.4804\n",
            "Semantic Entropy: 2.2969\n",
            "\n",
            "[5384/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي مدينة وُلد جون هنتلي في المملكة المتحدة؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3474\n",
            "Semantic Entropy: 1.2159\n",
            "\n",
            "[5385/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أي نادي لعب جون هنتلي معه في مجال كرة القدم؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1480\n",
            "Semantic Entropy: 0.1633\n",
            "✓ Saved partial progress after 5385 questions.\n",
            "\n",
            "[5386/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تأسست مجلة علم نفس الصحة؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5929\n",
            "Semantic Entropy: 0.8784\n",
            "\n",
            "[5387/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم أعضاء فريق التحرير الحالي للمجلة؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3448\n",
            "Semantic Entropy: 0.5968\n",
            "\n",
            "[5388/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو عامل التأثير لمجلة علم نفس الصحة في عام 2021؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.8949\n",
            "Semantic Entropy: 1.2342\n",
            "\n",
            "[5389/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الموضوعات التي تغطيها المجلة في مقالاتها؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4254\n",
            "Semantic Entropy: 0.7548\n",
            "\n",
            "[5390/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المحتوى الذي تضمنه العدد الذي نشرته المجلة في يوليو 2017؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.5260\n",
            "Semantic Entropy: 0.0947\n",
            "✓ Saved partial progress after 5390 questions.\n",
            "\n",
            "[5391/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مؤتمر مدريد لعام 1991؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3388\n",
            "Semantic Entropy: 1.2626\n",
            "\n",
            "[5392/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهداف المؤتمر؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.7312\n",
            "Semantic Entropy: 1.0040\n",
            "\n",
            "[5393/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هي الدول التي شاركت في رعاية المؤتمر؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4844\n",
            "Semantic Entropy: 0.5294\n",
            "\n",
            "[5394/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المحاولة التي تم إحيائها من قبل المجتمع الدولي من خلال المؤتمر؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6057\n",
            "Semantic Entropy: 1.7587\n",
            "\n",
            "[5395/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الدول المشاركة في المفاوضات الثنائية التي أعقبت المؤتمر؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5574\n",
            "Semantic Entropy: 1.9577\n",
            "✓ Saved partial progress after 5395 questions.\n",
            "\n",
            "[5396/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الدول التي لم تشارك في المفاوضات المتعددة الأطراف بشأن التعاون الإقليمي في موسكو؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5320\n",
            "Semantic Entropy: 1.3405\n",
            "\n",
            "[5397/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا قال وزير الخارجية الأمريكي جيمس بيكر في 22 مايو 1989؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.3591\n",
            "Semantic Entropy: 2.0178\n",
            "\n",
            "[5398/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الإشارة التي أخذها الناس من تصريح جيمس بيكر؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5038\n",
            "Semantic Entropy: 1.8356\n",
            "\n",
            "[5399/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي السياسة الرئيسية التي تم التحدث عنها في خطاب الرئيس جورج بوش الأب بعد حرب الخليج في 6 مارس 1991؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.2217\n",
            "Semantic Entropy: 1.9123\n",
            "\n",
            "[5400/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المحور الرئيسي لبرنامج مايكل أورين؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4873\n",
            "Semantic Entropy: 2.0134\n",
            "✓ Saved partial progress after 5400 questions.\n",
            "\n",
            "[5401/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى ولد إبراهيم أحمد العموري؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2792\n",
            "Semantic Entropy: 0.4691\n",
            "\n",
            "[5402/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'اين ولد ابراهيم احمد العموري؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.5285\n",
            "Semantic Entropy: 0.2211\n",
            "\n",
            "[5403/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي اغتيل ابراهيم احمد العموري؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4767\n",
            "Semantic Entropy: 1.9247\n",
            "\n",
            "[5404/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو اسم الفصيل العسكري الذي أسسه وقاده إبراهيم العموري خلال الثورة الفلسطينية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.7523\n",
            "Semantic Entropy: 0.9216\n",
            "\n",
            "[5405/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي جنسية إبراهيم العموري؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0823\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5405 questions.\n",
            "\n",
            "[5406/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي جائزة مالية قُدمت لمن يبلغ عن مكان تواجد إبراهيم العموري بعد محاولة اغتيال الضابط العسكري البريطاني؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2327\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5407/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف قُتِل إبراهيم العموري؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4876\n",
            "Semantic Entropy: 0.3037\n",
            "\n",
            "[5408/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد القتلى الفلسطينيين الذين قُتلوا مع إبراهيم العموري خلال عملية اغتياله؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2621\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5409/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو التكريم الذي تم منح إبراهيم العموري بعد وفاته؟\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.6361\n",
            "Semantic Entropy: 2.2853\n",
            "\n",
            "[5410/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو الشخص الذي ابتكر مصطلح الدوائر العروضية في علم العروض؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2475\n",
            "Semantic Entropy: 0.8590\n",
            "✓ Saved partial progress after 5410 questions.\n",
            "\n",
            "[5411/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' ما هو مفهوم الدائرة العروضية ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3851\n",
            "Semantic Entropy: 1.4284\n",
            "\n",
            "[5412/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف وصفها الخليل بن أحمد الفراهيدي؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5833\n",
            "Semantic Entropy: 1.5855\n",
            "\n",
            "[5413/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي التفعيلات وكيف وصفها الخليل بن أحمد الفراهيدي في علم العروض؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4960\n",
            "Semantic Entropy: 0.9584\n",
            "\n",
            "[5414/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المادة النشطة عصبيًا الطبيعية؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0673\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5415/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف تُصنع المواد النشطة عصبيًا الطبيعية؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3810\n",
            "Semantic Entropy: 1.3786\n",
            "✓ Saved partial progress after 5415 questions.\n",
            "\n",
            "[5416/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما الأفعال التي تؤثر فيها المواد النشطة عصبيًا الطبيعية؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3240\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5417/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي النواقل العصبية ؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2765\n",
            "Semantic Entropy: 0.3456\n",
            "\n",
            "[5418/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الهرمونات العصبية وكيف تعمل عن بُعد؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4537\n",
            "Semantic Entropy: 0.3217\n",
            "\n",
            "[5419/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا تتضمن المواد النشطة عصبيًا الطبيعية؟ '\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3319\n",
            "Semantic Entropy: 0.6095\n",
            "\n",
            "[5420/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور النواقل العصبية في النظام العصبي؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2450\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5420 questions.\n",
            "\n",
            "[5421/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي نمط ألعاب \"صمود الرجل الأخير\"؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4966\n",
            "Semantic Entropy: 1.1740\n",
            "\n",
            "[5422/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الهدف الأساسي في لعبة \"صمود الرجل الأخير\"؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3265\n",
            "Semantic Entropy: 0.8953\n",
            "\n",
            "[5423/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الفارق بين ألعاب منظور الشخص الأول وألعاب باتل رويال؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3153\n",
            "Semantic Entropy: 0.3245\n",
            "\n",
            "[5424/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تاريخ يوم 24 / 8؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0527\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5425/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو التقويم المستخدم لتحديد يوم 24 / 8 في السنوات الكبيسة ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2128\n",
            "Semantic Entropy: 0.2764\n",
            "✓ Saved partial progress after 5425 questions.\n",
            "\n",
            "[5426/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم يوما يتبقى في السنة بعد يوم 24 / 8  ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.6479\n",
            "Semantic Entropy: 0.5193\n",
            "\n",
            "[5427/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما ترتيب يوم 24 / 8 في السنوات البسيطة ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.2722\n",
            "Semantic Entropy: 1.6536\n",
            "\n",
            "[5428/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما ترتيب يوم 24 / 8 في السنوات الكبيسة ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2590\n",
            "Semantic Entropy: 0.3120\n",
            "\n",
            "[5429/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي عاصمة ولاية سوق أهراس في الجزائر؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1552\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5430/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا تلقب ولاية سوق أهراس بـ\"سوق الأُسُود\"؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5061\n",
            "Semantic Entropy: 1.9942\n",
            "✓ Saved partial progress after 5430 questions.\n",
            "\n",
            "[5431/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو أصل تسمية مدينة سوق أهراس؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6609\n",
            "Semantic Entropy: 1.6090\n",
            "\n",
            "[5432/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي اللغات المستخدمة في مدينة سوق أهراس؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3847\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5433/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الديانات المنتشرة في ولاية سوق أهراس؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3615\n",
            "Semantic Entropy: 0.3202\n",
            "\n",
            "[5434/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين تقع مدينة سوق أهراس في الجزائر؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1782\n",
            "Semantic Entropy: 0.6149\n",
            "\n",
            "[5435/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الولايات المجاورة لولاية سوق أهراس يحدها من الشمال ؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2906\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5435 questions.\n",
            "\n",
            "[5436/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الولايات المجاورة لولاية سوق أهراس يحدها من الغرب ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2711\n",
            "Semantic Entropy: 1.0064\n",
            "\n",
            "[5437/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الولايات المجاورة لولاية سوق أهراس يحدها من الشرق ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5190\n",
            "Semantic Entropy: 1.1998\n",
            "\n",
            "[5438/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الولايات المجاورة لولاية سوق أهراس يحدها من الجنوب؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4110\n",
            "Semantic Entropy: 0.8134\n",
            "\n",
            "[5439/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الدور التاريخي لمدينة سوق أهراس في الجزائر؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5129\n",
            "Semantic Entropy: 1.3721\n",
            "\n",
            "[5440/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الموقع الجغرافي لمدينة سوق أهراس في الجزائر؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2539\n",
            "Semantic Entropy: 0.8216\n",
            "✓ Saved partial progress after 5440 questions.\n",
            "\n",
            "[5441/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'سؤال 1: ما هي شركة تلفزيون مارفل؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3245\n",
            "Semantic Entropy: 0.6083\n",
            "\n",
            "[5442/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم نقل القسم التلفزيوني من شركة مارفل إنترتينمنت إلى استوديوهات مارفل؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 1.1043\n",
            "Semantic Entropy: 0.6451\n",
            "\n",
            "[5443/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي علامة خلفية تلفزيون مارفل حاليًا؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6508\n",
            "Semantic Entropy: 1.1763\n",
            "\n",
            "[5444/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المسلسل التلفزيوني الحي الوحيد الناجح من مارفل؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 1.2308\n",
            "Semantic Entropy: 1.7732\n",
            "\n",
            "[5445/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'سؤال 2: ما هي المجالات التي كانت تعمل فيها شركة تلفزيون مارفل؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3578\n",
            "Semantic Entropy: 0.8513\n",
            "✓ Saved partial progress after 5445 questions.\n",
            "\n",
            "[5446/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الثورة الصناعية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3735\n",
            "Semantic Entropy: 1.0411\n",
            "\n",
            "[5447/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العوامل التي أدت إلى نشوء الثورة الصناعية في أوروبا الغربية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4566\n",
            "Semantic Entropy: 0.8162\n",
            "\n",
            "[5448/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي التقنيات والاختراعات الرئيسية التي نشأت في فترة الثورة الصناعية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4982\n",
            "Semantic Entropy: 0.6225\n",
            "\n",
            "[5449/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف تأثرت عمليات التصنيع والإنتاج بوصول المكننة والتكنولوجيا الجديدة؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3063\n",
            "Semantic Entropy: 0.2785\n",
            "\n",
            "[5450/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور الطاقة البخارية والمائية في تقدم الثورة الصناعية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4377\n",
            "Semantic Entropy: 0.7067\n",
            "✓ Saved partial progress after 5450 questions.\n",
            "\n",
            "[5451/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العواقب البيئية للثورة الصناعية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4482\n",
            "Semantic Entropy: 0.9781\n",
            "\n",
            "[5452/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى وقعت معركة سقوط فاس؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.8170\n",
            "Semantic Entropy: 1.3263\n",
            "\n",
            "[5453/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو السبب وراء المعركة؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5175\n",
            "Semantic Entropy: 1.7381\n",
            "\n",
            "[5454/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم الزعيمان اللذان قادا المعسكرين المتصارعين؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.6176\n",
            "Semantic Entropy: 2.0781\n",
            "\n",
            "[5455/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما دور الدولة العثمانية في المعركة؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.7036\n",
            "Semantic Entropy: 2.1404\n",
            "✓ Saved partial progress after 5455 questions.\n",
            "\n",
            "[5456/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم بلغ عدد جيش القوات العثمانية التي توجهت من الجزائر؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3916\n",
            "Semantic Entropy: 0.9529\n",
            "\n",
            "[5457/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من قام بتشكيل قوات الزواوة ولماذا؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6297\n",
            "Semantic Entropy: 1.6058\n",
            "\n",
            "[5458/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تركيبة جيش المتوكل؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3675\n",
            "Semantic Entropy: 1.3451\n",
            "\n",
            "[5459/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تركيبة جيش القوات العثمانية؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3879\n",
            "Semantic Entropy: 1.1827\n",
            "\n",
            "[5460/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم الشخصيتان اللذان فروا إلى سوريا هربا من أخيهما عبد الله الغالب؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5297\n",
            "Semantic Entropy: 1.9047\n",
            "✓ Saved partial progress after 5460 questions.\n",
            "\n",
            "[5461/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم يوماً يتبقى في السنة بعد 13 يناير؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2489\n",
            "Semantic Entropy: 1.0952\n",
            "\n",
            "[5462/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تاريخ 13 يناير؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.1423\n",
            "Semantic Entropy: 0.4752\n",
            "\n",
            "[5463/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '\n",
            "كم يوماً في السنة الكبيسة بعد 10 يناير؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5946\n",
            "Semantic Entropy: 1.5087\n",
            "\n",
            "[5464/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي جنسية خوسيه لويس فاليينتي؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1980\n",
            "Semantic Entropy: 0.6082\n",
            "\n",
            "[5465/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد خوسيه لويس فاليينتي؟\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4701\n",
            "Semantic Entropy: 0.8745\n",
            "✓ Saved partial progress after 5465 questions.\n",
            "\n",
            "[5466/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز لعب خوسيه لويس فاليينتي في كرة القدم؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5819\n",
            "Semantic Entropy: 1.3838\n",
            "\n",
            "[5467/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي تاريخ ولد خوسيه لويس فاليينتي؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.6988\n",
            "Semantic Entropy: 2.2570\n",
            "\n",
            "[5468/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتم تحضير رقائق التُرتِيَّة؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4279\n",
            "Semantic Entropy: 2.0281\n",
            "\n",
            "[5469/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي مكونات رقائق التُرتِيَّة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4368\n",
            "Semantic Entropy: 1.5752\n",
            "\n",
            "[5470/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من أين يعود أصل التُرتِيَّة؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2260\n",
            "Semantic Entropy: 0.8727\n",
            "✓ Saved partial progress after 5470 questions.\n",
            "\n",
            "[5471/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفوائد التاريخية لرقائق التُرتِيَّة في صناعة الطعام المكسيكي؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.8091\n",
            "Semantic Entropy: 1.0159\n",
            "\n",
            "[5472/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هي ريبيكا ويب كارانزا وما دورها في شهرة رقائق التُرتِيَّة؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.2917\n",
            "Semantic Entropy: 1.9990\n",
            "\n",
            "[5473/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف تعزز رقائق التُرتِيَّة شعبيتها في صناعة الطعام في الولايات المتحدة؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.5828\n",
            "Semantic Entropy: 2.2752\n",
            "\n",
            "[5474/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الصلصات والنكهات التي يمكن تقديم رقائق التُرتِيَّة معها؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3907\n",
            "Semantic Entropy: 0.3345\n",
            "\n",
            "[5475/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تاريخ إقامة الانتخابات التشريعية الموريتانية لعام 2023؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2032\n",
            "Semantic Entropy: 0.9247\n",
            "✓ Saved partial progress after 5475 questions.\n",
            "\n",
            "[5476/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أنواع الانتخابات التي أجريت في موريتانيا خلال الانتخابات العامة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.2864\n",
            "Semantic Entropy: 1.3785\n",
            "\n",
            "[5477/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي النتيجة النهائية للشوط الأول من الانتخابات التشريعية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4222\n",
            "Semantic Entropy: 0.8674\n",
            "\n",
            "[5478/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي نسبة فوز حزب الإنصاف في الانتخابات النيابية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2142\n",
            "Semantic Entropy: 0.7279\n",
            "\n",
            "[5479/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفترة التي استمر فيها الشوط الثاني من الانتخابات البلدية؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.2408\n",
            "Semantic Entropy: 1.6230\n",
            "\n",
            "[5480/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو عدد المجالس الجهوية (الإقليمية) التي فاز بها حزب الإنصاف؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5165\n",
            "Semantic Entropy: 1.2467\n",
            "✓ Saved partial progress after 5480 questions.\n",
            "\n",
            "[5481/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي النسبة التي حصل عليها حزب الإنصاف في الانتخابات الجهوية؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0922\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5482/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد البلديات الكلي التي أجريت فيها انتخابات وكم عدد البلديات التي فاز بها حزب الإنصاف؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5047\n",
            "Semantic Entropy: 2.0289\n",
            "\n",
            "[5483/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو السِّبْجِيل؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3460\n",
            "Semantic Entropy: 1.2671\n",
            "\n",
            "[5484/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد الأنواع التي يضمها جنس السِّبْجِيل؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5872\n",
            "Semantic Entropy: 0.6063\n",
            "\n",
            "[5485/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي مناطق يتواجد السِّبْجِيل بشكل رئيسي؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1522\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5485 questions.\n",
            "\n",
            "[5486/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفصيلة التي ينتمي إليها السِّبْجِيل؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.6546\n",
            "Semantic Entropy: 1.0353\n",
            "\n",
            "[5487/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تصنيف فيلم حب بقوة ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5062\n",
            "Semantic Entropy: 0.7926\n",
            "\n",
            "[5488/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم أبطال حب بقوة ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3968\n",
            "Semantic Entropy: 1.2080\n",
            "\n",
            "[5489/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي سيتم عرض المسلسل ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3922\n",
            "Semantic Entropy: 0.6856\n",
            "\n",
            "[5490/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المنصة التي سيتم عرض المسلسل عليها؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1832\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5490 questions.\n",
            "\n",
            "[5491/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي \"الحيل\"؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5676\n",
            "Semantic Entropy: 1.1341\n",
            "\n",
            "[5492/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي مواد البناء المستخدمة في \"قلعة الحيل\"؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3295\n",
            "Semantic Entropy: 1.1936\n",
            "\n",
            "[5493/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو \"وادي الحيل\"؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0809\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5494/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' أين يقع جامع النور بالضبط في ولاية غليزان؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3484\n",
            "Semantic Entropy: 0.3036\n",
            "\n",
            "[5495/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى أُقيمت أول صلاة في الجامع بتسميته الحالية كجامع النور؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.2573\n",
            "Semantic Entropy: 1.6492\n",
            "✓ Saved partial progress after 5495 questions.\n",
            "\n",
            "[5496/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو جامع النور ؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4412\n",
            "Semantic Entropy: 0.6824\n",
            "\n",
            "[5497/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي جامعة النقل الوطنية ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6853\n",
            "Semantic Entropy: 1.6557\n",
            "\n",
            "[5498/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين تقع جامعة النقل الوطنية ؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0672\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5499/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي لغة الاستعلام والمعالجة المعرفية (KQML)؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4956\n",
            "Semantic Entropy: 1.6704\n",
            "\n",
            "[5500/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم تطوير KQML ولماذا؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5363\n",
            "Semantic Entropy: 2.0188\n",
            "✓ Saved partial progress after 5500 questions.\n",
            "\n",
            "[5501/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الغرض الرئيسي لاستخدام KQML؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4606\n",
            "Semantic Entropy: 1.3410\n",
            "\n",
            "[5502/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من قام بإدارة العمل على KQML؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6637\n",
            "Semantic Entropy: 0.9133\n",
            "\n",
            "[5503/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يمكن استخدام تنسيق وبروتوكول KQML للتفاعل مع نظام ذكي؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5372\n",
            "Semantic Entropy: 0.9477\n",
            "\n",
            "[5504/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الهدف من بناء الساحة؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4777\n",
            "Semantic Entropy: 1.1420\n",
            "\n",
            "[5505/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي  تحولت الساحة إلى سوق شعبي؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6934\n",
            "Semantic Entropy: 1.2563\n",
            "✓ Saved partial progress after 5505 questions.\n",
            "\n",
            "[5506/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'بماذا سميت الساحة بعد ان  تحولت إلى سوق شعبي؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6186\n",
            "Semantic Entropy: 1.7781\n",
            "\n",
            "[5507/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي أُعدم أعضاء في الساحة؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.7460\n",
            "Semantic Entropy: 1.6453\n",
            "\n",
            "[5508/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي بلازا فيخا أو الساحة القديمة؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2746\n",
            "Semantic Entropy: 0.8697\n",
            "\n",
            "[5509/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم يبلغ عدد سكان الساحة والمناطق المُحيطة بها ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3969\n",
            "Semantic Entropy: 1.8423\n",
            "\n",
            "[5510/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا كانت تسمي الساحة سابقا؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2757\n",
            "Semantic Entropy: 0.7819\n",
            "✓ Saved partial progress after 5510 questions.\n",
            "\n",
            "[5511/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي تم تشييد الساحة؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.9517\n",
            "Semantic Entropy: 1.5617\n",
            "\n",
            "[5512/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو ألاسم المستعار لماري جوزيف ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3263\n",
            "Semantic Entropy: 0.6522\n",
            "\n",
            "[5513/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو ماري جوزيف غابرييل أنطوان جوغاند باجيس؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5607\n",
            "Semantic Entropy: 1.9351\n",
            "\n",
            "[5514/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد ماري جوزيف غابرييل ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5635\n",
            "Semantic Entropy: 1.4045\n",
            "\n",
            "[5515/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين قضي ماري جوزيف ايام طفولتة؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3832\n",
            "Semantic Entropy: 1.7671\n",
            "✓ Saved partial progress after 5515 questions.\n",
            "\n",
            "[5516/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'بماذا أشتهر ماري جوزيف ؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5102\n",
            "Semantic Entropy: 2.1389\n",
            "\n",
            "[5517/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو عبد الله بن ديريه؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.2987\n",
            "Semantic Entropy: 1.5882\n",
            "\n",
            "[5518/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الجهود التي قادها عبد الله بن ديريه لاستعادة أراضي المعاهدة المفقودة \"هود\"؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4378\n",
            "Semantic Entropy: 1.8436\n",
            "\n",
            "[5519/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأهداف التي سعى إليها الحزب \"الرابطة الوطنية الصومالية\"؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4783\n",
            "Semantic Entropy: 1.2512\n",
            "\n",
            "[5520/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المطلب الذي قدمه السلطان عبد الله إلى المجلس التشريعي الناشئ في إقليم صوماليلاند؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6452\n",
            "Semantic Entropy: 1.8553\n",
            "✓ Saved partial progress after 5520 questions.\n",
            "\n",
            "[5521/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو إدي ولستنهولم؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3282\n",
            "Semantic Entropy: 1.6360\n",
            "\n",
            "[5522/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد إدي ولستنهولم؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.4749\n",
            "Semantic Entropy: 2.1293\n",
            "\n",
            "[5523/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد إدي ولستنهولم؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5573\n",
            "Semantic Entropy: 0.8125\n",
            "\n",
            "[5524/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تأسست ولاية البحر الأحمر؟\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0548\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5525/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي ولاية البحر الأحمر؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1633\n",
            "Semantic Entropy: 0.4780\n",
            "✓ Saved partial progress after 5525 questions.\n",
            "\n",
            "[5526/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو موقع ولاية البحر الأحمر؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2699\n",
            "Semantic Entropy: 0.5635\n",
            "\n",
            "[5527/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الولايات التي تحد ولاية البحر الأحمر؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2182\n",
            "Semantic Entropy: 0.3596\n",
            "\n",
            "[5528/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو عدد السكان في ولاية البحر الأحمر؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5468\n",
            "Semantic Entropy: 1.2302\n",
            "\n",
            "[5529/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي اللغة الرئيسية في ولاية البحر الأحمر؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1626\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5530/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العاصمة لولاية البحر الأحمر؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2551\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5530 questions.\n",
            "\n",
            "[5531/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم إنشاء مجلس الشؤون العامة؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1340\n",
            "Semantic Entropy: 0.4116\n",
            "\n",
            "[5532/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من يشارك في اجتماعات مجلس الشؤون العامة؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2324\n",
            "Semantic Entropy: 0.4507\n",
            "\n",
            "[5533/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العلاقة بين مجلس الشؤون العامة والمجلس الأوروبي؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4586\n",
            "Semantic Entropy: 1.0772\n",
            "\n",
            "[5534/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي القضايا الأساسية التي يمكن أن يتناولها مجلس الشؤون العامة؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4046\n",
            "Semantic Entropy: 1.4784\n",
            "\n",
            "[5535/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم مرة يتم اجتماع مجلس الشؤون العامة؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4424\n",
            "Semantic Entropy: 1.0952\n",
            "✓ Saved partial progress after 5535 questions.\n",
            "\n",
            "[5536/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو بكيني الأميرة ليا؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6362\n",
            "Semantic Entropy: 1.6793\n",
            "\n",
            "[5537/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي كمبانية جَيَّان؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4198\n",
            "Semantic Entropy: 1.9624\n",
            "\n",
            "[5538/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد النواحي في مقاطعة جيان الإسبانية؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3847\n",
            "Semantic Entropy: 0.6246\n",
            "\n",
            "[5539/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تأسست كمبانية جَيَّان؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2247\n",
            "Semantic Entropy: 1.1767\n",
            "\n",
            "[5540/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى بدأ الاهتمام الرسمي بالمتاحف الأثرية في المملكة العربية السعودية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4707\n",
            "Semantic Entropy: 1.3497\n",
            "✓ Saved partial progress after 5540 questions.\n",
            "\n",
            "[5541/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المنظمة التي شاركت في تأسيسها السعودية للتربية والعلم والثقافة؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3185\n",
            "Semantic Entropy: 0.7461\n",
            "\n",
            "[5542/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المعاهدة الثقافية التي وقعتها السعودية في إطار جامعة الدول العربية؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3599\n",
            "Semantic Entropy: 1.3257\n",
            "\n",
            "[5543/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو آش بيكر؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6958\n",
            "Semantic Entropy: 1.1813\n",
            "\n",
            "[5544/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي جنسية آش بيكر؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3070\n",
            "Semantic Entropy: 0.1283\n",
            "\n",
            "[5545/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز آش بيكر؟'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.6319\n",
            "Semantic Entropy: 2.2547\n",
            "✓ Saved partial progress after 5545 questions.\n",
            "\n",
            "[5546/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد آش بيكر؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6757\n",
            "Semantic Entropy: 1.7885\n",
            "\n",
            "[5547/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد آش بيكر؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 1.4034\n",
            "Semantic Entropy: 1.5058\n",
            "\n",
            "[5548/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا عن مشاركاته الدولية ؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.6965\n",
            "Semantic Entropy: 1.9834\n",
            "\n",
            "[5549/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو أسم النادي الذي لعب له آش بيكر؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5381\n",
            "Semantic Entropy: 1.3063\n",
            "\n",
            "[5550/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من قام بنحت نموذج القدس البارز؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5218\n",
            "Semantic Entropy: 0.9933\n",
            "✓ Saved partial progress after 5550 questions.\n",
            "\n",
            "[5551/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هونموذج القدس البارز؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 1.0747\n",
            "Semantic Entropy: 1.8779\n",
            "\n",
            "[5552/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أبعاد نموذج القدس؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.7554\n",
            "Semantic Entropy: 2.1100\n",
            "\n",
            "[5553/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا تم تصميم هذا النموذج؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5823\n",
            "Semantic Entropy: 1.1126\n",
            "\n",
            "[5554/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي عام عرض نموذج القدس في معرض فيينا العالمي؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5012\n",
            "Semantic Entropy: 1.0266\n",
            "\n",
            "[5555/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مسرح الدسمة؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.4240\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5555 questions.\n",
            "\n",
            "[5556/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي دولة يشتهر مسرح الدسمة؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1650\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5557/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفعاليات التي يستضيفها مسرح الدسمة؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4260\n",
            "Semantic Entropy: 0.3523\n",
            "\n",
            "[5558/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تواريخ تأسيس مدرسة بيت إسعاد الطفولة؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2091\n",
            "Semantic Entropy: 0.7344\n",
            "\n",
            "[5559/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي مدرسة بيت إسعاد الطفولة؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.6081\n",
            "Semantic Entropy: 2.1392\n",
            "\n",
            "[5560/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من قام بتأسيس مدرسة بيت إسعاد الطفولة؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.8505\n",
            "Semantic Entropy: 2.2257\n",
            "✓ Saved partial progress after 5560 questions.\n",
            "\n",
            "[5561/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهداف مدرسة بيت إسعاد الطفولة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.8024\n",
            "Semantic Entropy: 1.5628\n",
            "\n",
            "[5562/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين تقع جامعة دنيبرو الوطنية للنقل بالسكك الحديدية؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1738\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5563/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي تأسست جامعة دنيبرو الوطنية للنقل بالسكك الحديدية؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5370\n",
            "Semantic Entropy: 1.0861\n",
            "\n",
            "[5564/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي فئة ريفر؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.7561\n",
            "Semantic Entropy: 2.1796\n",
            "\n",
            "[5565/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد الفرقاطات التي تم إطلاقها كجزء من فئة ريفر؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3879\n",
            "Semantic Entropy: 0.3004\n",
            "✓ Saved partial progress after 5565 questions.\n",
            "\n",
            "[5566/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي استخدامات الفرقاطات من فئة ريفر؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5039\n",
            "Semantic Entropy: 0.6079\n",
            "\n",
            "[5567/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أي دول خدمت الفرقاطات من هذه الفئة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5675\n",
            "Semantic Entropy: 1.6797\n",
            "\n",
            "[5568/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى قدمت البحرية الملكية أولى طلباتها لسفن الفئة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.7438\n",
            "Semantic Entropy: 1.1982\n",
            "\n",
            "[5569/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الكروكنبوش؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.3642\n",
            "Semantic Entropy: 2.1735\n",
            "\n",
            "[5570/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتم صنع الكروكنبوش؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3555\n",
            "Semantic Entropy: 1.3332\n",
            "✓ Saved partial progress after 5570 questions.\n",
            "\n",
            "[5571/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المكونات الأساسية للكروكنبوش؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5335\n",
            "Semantic Entropy: 0.9194\n",
            "\n",
            "[5572/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي مناسبات تقدم عادة الكروكنبوش؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4132\n",
            "Semantic Entropy: 0.3373\n",
            "\n",
            "[5573/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما معنى الاسم \"كروكمبوش\" وما هو المصطلح الإنجليزي المعروف لهذه الحلوى؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4480\n",
            "Semantic Entropy: 1.7407\n",
            "\n",
            "[5574/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من يُعتقد أنه اخترع الكروكنبوش ؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.3137\n",
            "Semantic Entropy: 1.9513\n",
            "\n",
            "[5575/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو روس لايدلو؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4181\n",
            "Semantic Entropy: 1.8558\n",
            "✓ Saved partial progress after 5575 questions.\n",
            "\n",
            "[5576/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي مركز يلعب روس لايدلو في كرة القدم؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5929\n",
            "Semantic Entropy: 1.4911\n",
            "\n",
            "[5577/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى ولد روس لايدلو؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.7211\n",
            "Semantic Entropy: 2.1750\n",
            "\n",
            "[5578/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي نادي بريطاني ولد روس لايدلو؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4848\n",
            "Semantic Entropy: 1.2929\n",
            "\n",
            "[5579/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو عبيد الله بن طاهر الحسني الروقي الطوسي؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4686\n",
            "Semantic Entropy: 1.5934\n",
            "\n",
            "[5580/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو الشيخ الذي تلقى عبيد الله العلم منه؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4840\n",
            "Semantic Entropy: 1.9405\n",
            "✓ Saved partial progress after 5580 questions.\n",
            "\n",
            "[5581/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو اللقب الذي أشهر به عبيد الله الطوسي؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5938\n",
            "Semantic Entropy: 1.6391\n",
            "\n",
            "[5582/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي نسبة الطوسي في اسمه؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.8348\n",
            "Semantic Entropy: 1.8172\n",
            "\n",
            "[5583/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي القمة الهرمية؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5608\n",
            "Semantic Entropy: 1.8819\n",
            "\n",
            "[5584/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتكون القمة الهرمية؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4842\n",
            "Semantic Entropy: 1.8048\n",
            "\n",
            "[5585/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو التأثير الرئيسي الذي يؤدي إلى تشكل القمم الهرمية؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6929\n",
            "Semantic Entropy: 1.7881\n",
            "✓ Saved partial progress after 5585 questions.\n",
            "\n",
            "[5586/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور تباعد الأنهار الجليدية في تكوين القمم الهرمية؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3475\n",
            "Semantic Entropy: 1.4627\n",
            "\n",
            "[5587/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تأسست الجمعية الوطنية للفيزيائيين من أصل إسباني (NSHP)؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3200\n",
            "Semantic Entropy: 1.5475\n",
            "\n",
            "[5588/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأهداف الرئيسية لتأسيس الجمعية الوطنية للفيزيائيين من أصل إسباني؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.6337\n",
            "Semantic Entropy: 0.3523\n",
            "\n",
            "[5589/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين عقد الاجتماع التأسيسي الأول للجمعية؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0149\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5590/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المنظمات التي اجتمعت NSHP معها سنويًا منذ 1997؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.2829\n",
            "Semantic Entropy: 1.3603\n",
            "✓ Saved partial progress after 5590 questions.\n",
            "\n",
            "[5591/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الغرض من تشجيع الجمعية دراسة الفيزياء بين الطلاب ذوي الأصول الأسبانية؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1387\n",
            "Semantic Entropy: 0.2635\n",
            "\n",
            "[5592/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف تقوم الجمعية بتحديد ونشر إنجازات أعضاء هيئة التدريس والطلاب في مجال الفيزياء؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4146\n",
            "Semantic Entropy: 1.4526\n",
            "\n",
            "[5593/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور الجمعية في تحقيق أهدافها المتعلقة بالتنوع والشمول في مجتمع الفيزياء؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5929\n",
            "Semantic Entropy: 1.2088\n",
            "\n",
            "[5594/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو اربية؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4642\n",
            "Semantic Entropy: 1.0524\n",
            "\n",
            "[5595/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من اي فصيلة يكون نبات الاربية؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.7250\n",
            "Semantic Entropy: 1.8442\n",
            "✓ Saved partial progress after 5595 questions.\n",
            "\n",
            "[5596/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي وصف الاربية  لاول مرة بانه جنس نبات؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5206\n",
            "Semantic Entropy: 0.5140\n",
            "\n",
            "[5597/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الموطن الاصلي لنبات الاربية؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3691\n",
            "Semantic Entropy: 1.8180\n",
            "\n",
            "[5598/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو شبتاي تسفي أو سبطاي سوي؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.7395\n",
            "Semantic Entropy: 1.6065\n",
            "\n",
            "[5599/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية شبتاي تسفي أو سبطاي سوي في تاريخ اليهودية؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5925\n",
            "Semantic Entropy: 2.1238\n",
            "\n",
            "[5600/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف وصل شبتاي تسفي إلى اعتقاده بأن المسيح سيظهر في عام 1648؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1981\n",
            "Semantic Entropy: 0.3171\n",
            "✓ Saved partial progress after 5600 questions.\n",
            "\n",
            "[5601/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي ردة فعل الحاخام جوزيف اسكوبا على ادعاء شبتاي تسفي؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0294\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5602/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا نُقل شبتاي تسفي إلى جزيرة آيدوس؟\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3619\n",
            "Semantic Entropy: 1.7368\n",
            "\n",
            "[5603/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مكان بيل هيل ميتنج هاوس ؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4129\n",
            "Semantic Entropy: 0.7835\n",
            "\n",
            "[5604/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' بيل هيل ميتنج هاوس متى تم بناؤه؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4627\n",
            "Semantic Entropy: 1.3077\n",
            "\n",
            "[5605/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا تم إدراج بيل هيل ميتنج هاوس في السجل الوطني للأماكن التاريخية؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4466\n",
            "Semantic Entropy: 1.1020\n",
            "✓ Saved partial progress after 5605 questions.\n",
            "\n",
            "[5606/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتكون هيكل بيل هيل ميتنج هاوس؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2257\n",
            "Semantic Entropy: 0.4328\n",
            "\n",
            "[5607/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا تم بناء دار الاجتماعات الأصلية وما حدث لها؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5812\n",
            "Semantic Entropy: 2.1381\n",
            "\n",
            "[5608/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم إعادة إحياء بيل هيل ميتنج هاوس للخدمات السنوية؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 1.6437\n",
            "Semantic Entropy: 1.5949\n",
            "\n",
            "[5609/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو نادي كيريتاريو؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2161\n",
            "Semantic Entropy: 0.8325\n",
            "\n",
            "[5610/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين يوجد مقر نادي كيريتاريو؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3015\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5610 questions.\n",
            "\n",
            "[5611/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من بعض النجوم البارزين الذين انضموا إلى نادي كيريتاريو؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.7799\n",
            "Semantic Entropy: 1.5022\n",
            "\n",
            "[5612/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي البطولات الرئيسية التي شارك فيها نادي كيريتاريو؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4353\n",
            "Semantic Entropy: 1.2958\n",
            "\n",
            "[5613/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد تياغو ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3805\n",
            "Semantic Entropy: 1.5816\n",
            "\n",
            "[5614/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد تياغو ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.8708\n",
            "Semantic Entropy: 1.6041\n",
            "\n",
            "[5615/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو تياغو ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.2432\n",
            "Semantic Entropy: 1.6801\n",
            "✓ Saved partial progress after 5615 questions.\n",
            "\n",
            "[5616/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز اللاعب تياغو ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2927\n",
            "Semantic Entropy: 0.2501\n",
            "\n",
            "[5617/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأندية التي لعب معها تياغو ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4023\n",
            "Semantic Entropy: 0.6178\n",
            "\n",
            "[5618/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المواد التي استخدمها الشعوب الأصلية في كندا كعملة قبل التواصل مع الأوروبيين؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5145\n",
            "Semantic Entropy: 1.9053\n",
            "\n",
            "[5619/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى بدأت كندا في استخدام العملات المعدنية والأوراق النقدية؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.1549\n",
            "Semantic Entropy: 1.4534\n",
            "\n",
            "[5620/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العملة التي تم استخدامها في كندا خلال الاستعمار البريطاني؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2538\n",
            "Semantic Entropy: 0.4470\n",
            "✓ Saved partial progress after 5620 questions.\n",
            "\n",
            "[5621/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى بدأ إصدار الدولار الكندي كوحدة نقدية؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0866\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5622/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أحدث التطورات في تاريخ استخدام العملات في كندا؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.5119\n",
            "Semantic Entropy: 2.2776\n",
            "\n",
            "[5623/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي مسفرة؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5266\n",
            "Semantic Entropy: 0.8681\n",
            "\n",
            "[5624/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المعنى اللغوي لاسم \"مسفرة\"؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3118\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5625/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المسافة بين مسفرة ومدينة بيشة؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.3921\n",
            "Semantic Entropy: 1.9822\n",
            "✓ Saved partial progress after 5625 questions.\n",
            "\n",
            "[5626/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو أومبرتو امبورتا ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2843\n",
            "Semantic Entropy: 0.7573\n",
            "\n",
            "[5627/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز اللاعب أومبرتو امبورتا ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3775\n",
            "Semantic Entropy: 1.3595\n",
            "\n",
            "[5628/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد أومبرتو امبورتا ؟'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.4060\n",
            "Semantic Entropy: 2.2884\n",
            "\n",
            "[5629/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد أومبرتو امبورتا ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5053\n",
            "Semantic Entropy: 1.4872\n",
            "\n",
            "[5630/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي النوادي التي لعب معها أومبرتو امبورتا ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5951\n",
            "Semantic Entropy: 1.3978\n",
            "✓ Saved partial progress after 5630 questions.\n",
            "\n",
            "[5631/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو موضوع البحث في اقتصاديات أمن المعلومات؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4670\n",
            "Semantic Entropy: 1.4329\n",
            "\n",
            "[5632/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي النماذج الاقتصادية المستخدمة في دراسة أمن المعلومات؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6619\n",
            "Semantic Entropy: 1.5888\n",
            "\n",
            "[5633/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي السؤال الأساسي الذي تطرحه اقتصاديات الأمن؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4652\n",
            "Semantic Entropy: 1.0849\n",
            "\n",
            "[5634/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور النقاط الضعيفة في اقتصاديات الأمن؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3502\n",
            "Semantic Entropy: 1.3472\n",
            "\n",
            "[5635/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يمكن للاقتصاديات أن تساعد في صنع القرارات التصميمية في الهندسة الأمنية؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4180\n",
            "Semantic Entropy: 0.5959\n",
            "✓ Saved partial progress after 5635 questions.\n",
            "\n",
            "[5636/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مفهوم برهان العمل في سياق أمن المعلومات؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5576\n",
            "Semantic Entropy: 1.7054\n",
            "\n",
            "[5637/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الاكتشافات الهامة التي تم الوصول إليها في دراسة العلاقة بين الخصوصية وتسوية الأسعار؟\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5287\n",
            "Semantic Entropy: 1.6172\n",
            "\n",
            "[5638/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي تاسست بي بي سي أو هيئة الإذاعة البريطانية؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.6438\n",
            "Semantic Entropy: 0.5860\n",
            "\n",
            "[5639/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي السياسة التي تتبعها بي بي سي في تناول الأخبار؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4442\n",
            "Semantic Entropy: 0.4493\n",
            "\n",
            "[5640/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأسماء العامية التي يُعرف بها بي بي سي؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2177\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5640 questions.\n",
            "\n",
            "[5641/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الشركة التي رعت أول بث مباشر في بريطانيا عام 1920؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5984\n",
            "Semantic Entropy: 1.6319\n",
            "\n",
            "[5642/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي التوصيات التي قدمتها لجنة سايكس لحل الضائقة المالية التي تعرضت لها هيئة الإذاعة البريطانية؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3334\n",
            "Semantic Entropy: 1.0450\n",
            "\n",
            "[5643/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الجهات التي عارضت توسع إذاعات تشيلمسفورد عام 1920؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5624\n",
            "Semantic Entropy: 1.4994\n",
            "\n",
            "[5644/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا كان موضوع دراسة لجنة كروفورد في منتصف عام 1925؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.4489\n",
            "Semantic Entropy: 2.1776\n",
            "\n",
            "[5645/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي بي بي سي؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3517\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5645 questions.\n",
            "\n",
            "[5646/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تاريخ حدوث كسوف جزئي للشمس في عام 2058؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3617\n",
            "Semantic Entropy: 1.6090\n",
            "\n",
            "[5647/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تكرار الكسوفات في سلسلة ساروس 157؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.9408\n",
            "Semantic Entropy: 1.3861\n",
            "\n",
            "[5648/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي فترة تكرار دورة اينكس الطويلة؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.7932\n",
            "Semantic Entropy: 1.5863\n",
            "\n",
            "[5649/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد الدورات في سلسلة تريتوس؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5791\n",
            "Semantic Entropy: 0.4073\n",
            "\n",
            "[5650/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي فترة تكرار سلسلة ميتونيك؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 1.0277\n",
            "Semantic Entropy: 2.0700\n",
            "✓ Saved partial progress after 5650 questions.\n",
            "\n",
            "[5651/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تعرف كسوف الشمس؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1988\n",
            "Semantic Entropy: 0.1873\n",
            "\n",
            "[5652/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تصنيف فيلم قلبي من الظلام؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.9783\n",
            "Semantic Entropy: 0.9165\n",
            "\n",
            "[5653/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي قصة الفيلم ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5123\n",
            "Semantic Entropy: 1.6869\n",
            "\n",
            "[5654/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي عرض الفيلم لأول مرة؟'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.8522\n",
            "Semantic Entropy: 2.2603\n",
            "\n",
            "[5655/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد أندرسون ساليس ؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.8403\n",
            "Semantic Entropy: 1.9919\n",
            "✓ Saved partial progress after 5655 questions.\n",
            "\n",
            "[5656/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد أندرسون ساليس ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.7743\n",
            "Semantic Entropy: 0.7900\n",
            "\n",
            "[5657/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأندية التي لعب معها أندرسون ساليس ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3301\n",
            "Semantic Entropy: 1.1574\n",
            "\n",
            "[5658/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو أندرسون ساليس ؟'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.5885\n",
            "Semantic Entropy: 2.2769\n",
            "\n",
            "[5659/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز اللاعب أندرسون ساليس ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.2795\n",
            "Semantic Entropy: 1.4883\n",
            "\n",
            "[5660/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو فيلم \"لمَتارِيس\"؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4088\n",
            "Semantic Entropy: 1.5418\n",
            "✓ Saved partial progress after 5660 questions.\n",
            "\n",
            "[5661/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم بث الفيلم لأول مرة؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5334\n",
            "Semantic Entropy: 1.3826\n",
            "\n",
            "[5662/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية الفيلم بالنسبة للمشاهدين العرب؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.7075\n",
            "Semantic Entropy: 1.7185\n",
            "\n",
            "[5663/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية الفيلم بالنسبة لليهود الإسرائيليين؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.7234\n",
            "Semantic Entropy: 1.7077\n",
            "\n",
            "[5664/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى جاء لويفي بالفكرة وراء الفيلم؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.8271\n",
            "Semantic Entropy: 1.7402\n",
            "\n",
            "[5665/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو النشيد الوطني الألماني ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1313\n",
            "Semantic Entropy: 0.2622\n",
            "✓ Saved partial progress after 5665 questions.\n",
            "\n",
            "[5666/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المقطوعة الموسيقية التي تم تركيبها على كلمات النشيد؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4270\n",
            "Semantic Entropy: 1.3620\n",
            "\n",
            "[5667/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفقرات التي يتم غناؤها من النشيد الوطني الألماني اليوم؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1576\n",
            "Semantic Entropy: 0.4379\n",
            "\n",
            "[5668/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا تم حظر غناء الفقرتين الأوليين من النشيد في ألمانيا الغربية؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4624\n",
            "Semantic Entropy: 1.6799\n",
            "\n",
            "[5669/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي النقطة التي استغلها النازيون في النشيد الوطني الألماني؟'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.6299\n",
            "Semantic Entropy: 2.2412\n",
            "\n",
            "[5670/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم إلغاء مكانة النشيد الرسمية في ألمانيا بعد الحرب العالمية الثانية؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4811\n",
            "Semantic Entropy: 0.0820\n",
            "✓ Saved partial progress after 5670 questions.\n",
            "\n",
            "[5671/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو النشيد الذي اعتمدته ألمانيا الشرقية كنشيد وطني بعد الحرب العالمية الثانية؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.6111\n",
            "Semantic Entropy: 1.9627\n",
            "\n",
            "[5672/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الموقف الرسمي الحالي للفقرة الثالثة من النشيد الوطني الألماني؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.5849\n",
            "Semantic Entropy: 0.1340\n",
            "\n",
            "[5673/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ومتى تم كتابة النشيد الوطني الالماني؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.8142\n",
            "Semantic Entropy: 0.7288\n",
            "\n",
            "[5674/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي نظرية الانتقاء النسيلي في علم المناعة؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5478\n",
            "Semantic Entropy: 1.7808\n",
            "\n",
            "[5675/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو الطبيب الأسترالي الذي قام بصياغة نظرية الانتقاء النسيلي وفي أي عام؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4681\n",
            "Semantic Entropy: 1.3168\n",
            "✓ Saved partial progress after 5675 questions.\n",
            "\n",
            "[5676/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الهدف الرئيسي لوظائف خلايا الجهاز المناعي؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2973\n",
            "Semantic Entropy: 0.1698\n",
            "\n",
            "[5677/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الخلايا الليمفاوية وما هو دورها في استجابة جهاز المناعة؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3152\n",
            "Semantic Entropy: 0.5868\n",
            "\n",
            "[5678/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية النظرية النموذجية للانتقاء النسيلي في دراسة استجابة جهاز المناعة للعدوى؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4045\n",
            "Semantic Entropy: 0.6930\n",
            "\n",
            "[5679/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو جوفانـّي أنطونيو كاناليتو؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5020\n",
            "Semantic Entropy: 1.2911\n",
            "\n",
            "[5680/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي فترة عاش كاناليتو؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5406\n",
            "Semantic Entropy: 0.7336\n",
            "✓ Saved partial progress after 5680 questions.\n",
            "\n",
            "[5681/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي مدينة ولد'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.6239\n",
            "Semantic Entropy: 0.7544\n",
            "\n",
            "[5682/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا يعني المَدِينية في علاقة بأعمال كاناليتو؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.8741\n",
            "Semantic Entropy: 1.1961\n",
            "\n",
            "[5683/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي بعض الشواهد المشهورة لأعمال كاناليتو التي تصور البندقية؟'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.5968\n",
            "Semantic Entropy: 2.2917\n",
            "\n",
            "[5684/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مصطلح في علم الحوسبة؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.8097\n",
            "Semantic Entropy: 1.2479\n",
            "\n",
            "[5685/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا ينتج عن علم الحوسبة ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4465\n",
            "Semantic Entropy: 1.1838\n",
            "✓ Saved partial progress after 5685 questions.\n",
            "\n",
            "[5686/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو ارخوبازان ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4443\n",
            "Semantic Entropy: 1.4408\n",
            "\n",
            "[5687/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المملكة التي تولي  حكمها ارخوبازان ؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.4167\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5688/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف استفاد كاتو الأكبر من تصرفات الملك ارخوبازان؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.1799\n",
            "Semantic Entropy: 0.9402\n",
            "\n",
            "[5689/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى سيحدث كسوف جزئي للشمس في عام 2025؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1474\n",
            "Semantic Entropy: 0.5838\n",
            "\n",
            "[5690/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي سيتكون نقطة الحضيض في أمريكا وأوروبا؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3647\n",
            "Semantic Entropy: 0.8291\n",
            "✓ Saved partial progress after 5690 questions.\n",
            "\n",
            "[5691/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين سوف يمر الخسوف الكلي؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2170\n",
            "Semantic Entropy: 0.7474\n",
            "\n",
            "[5692/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو كارل شتومبف ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4063\n",
            "Semantic Entropy: 1.7585\n",
            "\n",
            "[5693/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد كارل شتومبف ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3553\n",
            "Semantic Entropy: 1.7134\n",
            "\n",
            "[5694/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي توفي كارل شتومبف ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4102\n",
            "Semantic Entropy: 1.4377\n",
            "\n",
            "[5695/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'بماذا أشتهر كارل شتومبف ؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.3776\n",
            "Semantic Entropy: 1.9889\n",
            "✓ Saved partial progress after 5695 questions.\n",
            "\n",
            "[5696/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو جيرو بايسنز؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4381\n",
            "Semantic Entropy: 1.8193\n",
            "\n",
            "[5697/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد جيرو بايسنز؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.8099\n",
            "Semantic Entropy: 1.9819\n",
            "\n",
            "[5698/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي توفي جيرو بايسنز؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.6610\n",
            "Semantic Entropy: 2.0842\n",
            "\n",
            "[5699/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو النادي الذي لعب فيه جيرو ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2715\n",
            "Semantic Entropy: 0.4812\n",
            "\n",
            "[5700/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المنتخب الذي دربه جيرو؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0169\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5700 questions.\n",
            "\n",
            "[5701/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المده التي درب فيها جيرو منتخب المانيا للسيدات؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4863\n",
            "Semantic Entropy: 0.7923\n",
            "\n",
            "[5702/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي إحدى الألقاب التي حققها كمدرب لمنتخب ألمانيا للسيدات؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4959\n",
            "Semantic Entropy: 1.1955\n",
            "\n",
            "[5703/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تولى جيرو بايسنز إدارة مرافق تدريب المدربين؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 1.4889\n",
            "Semantic Entropy: 2.0782\n",
            "\n",
            "[5704/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفكرة الأولى التي استحدثتها شبكة الـCNN؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.6543\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5705/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي شبكات القنوات الأكثر انتشارًا ومشاهدةً على مدار 24 ساعة في العالم؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0176\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5705 questions.\n",
            "\n",
            "[5706/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي القنوات الأخرى التي امتدت إليها شبكة CNN؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.7541\n",
            "Semantic Entropy: 1.2304\n",
            "\n",
            "[5707/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي القنوات الأخرى التي تنافس قناة CNN؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5183\n",
            "Semantic Entropy: 1.1850\n",
            "\n",
            "[5708/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو سبب رؤية بعض الناس للتغطية الأخبارية لمراسلي CNN من وجهة نظر أمريكية؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.8819\n",
            "Semantic Entropy: 1.7918\n",
            "\n",
            "[5709/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور المذيع (انكور كارول لين) في سباق قناة CNN لبث أنباء هجمات 11 سبتمبر على برجي التجارة العالمي؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4219\n",
            "Semantic Entropy: 0.8631\n",
            "\n",
            "[5710/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '\n",
            "كيف تعرف قناة CNN بموقعها الأول للأخبار والمعلومات على الأنترنت؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5462\n",
            "Semantic Entropy: 1.0898\n",
            "✓ Saved partial progress after 5710 questions.\n",
            "\n",
            "[5711/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي شركة تملك منظومة تيرنر للبثّ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5683\n",
            "Semantic Entropy: 0.7293\n",
            "\n",
            "[5712/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم إطلاق قناة CNN؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5926\n",
            "Semantic Entropy: 1.0250\n",
            "\n",
            "[5713/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '\n",
            "ما هي الاتهامات التي وجهت إلى قناة CNN خلال حرب الخليج؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5727\n",
            "Semantic Entropy: 1.2618\n",
            "\n",
            "[5714/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المبادرات التي اتخذتها قناة CNN للاستجابة لطلبات المشاهدين الغير أمريكيين؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5160\n",
            "Semantic Entropy: 1.5119\n",
            "\n",
            "[5715/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '1. ما هو حصار بومبي الكبير للقدس؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4325\n",
            "Semantic Entropy: 1.8234\n",
            "✓ Saved partial progress after 5715 questions.\n",
            "\n",
            "[5716/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '2. من كان الإمبراطور الروماني الذي فرض الحصار؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2161\n",
            "Semantic Entropy: 0.4744\n",
            "\n",
            "[5717/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '3. ما سبب فرض الحصار على القدس؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4642\n",
            "Semantic Entropy: 1.3785\n",
            "\n",
            "[5718/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '4. متى وقع حصار بومبي الكبير للقدس؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5653\n",
            "Semantic Entropy: 1.5332\n",
            "\n",
            "[5719/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '5. ما هي الحرب التي سبقت فرض الحصار؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5148\n",
            "Semantic Entropy: 1.1368\n",
            "\n",
            "[5720/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '6. من قام بانتصار في الحرب الميثراداتسية الثالثة؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3378\n",
            "Semantic Entropy: 0.5841\n",
            "✓ Saved partial progress after 5720 questions.\n",
            "\n",
            "[5721/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '7. ماذا حدث لملكة الحشمونائيم سالومي ألكسندرا؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5774\n",
            "Semantic Entropy: 1.2684\n",
            "\n",
            "[5722/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '8. ماذا فعل أريسطوبولس بأخيه هيركانوس؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.6344\n",
            "Semantic Entropy: 0.2046\n",
            "\n",
            "[5723/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '9. من قدم المساعدة لهيركانوس لمواجهة أريسطوبولس؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1315\n",
            "Semantic Entropy: 0.2913\n",
            "\n",
            "[5724/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '10. كم عدد الجنود الذين أرسلهم حارثة الثالث لمساعدة هيركانوس؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5865\n",
            "Semantic Entropy: 1.1294\n",
            "\n",
            "[5725/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الليثيوم؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2455\n",
            "Semantic Entropy: 1.0889\n",
            "✓ Saved partial progress after 5725 questions.\n",
            "\n",
            "[5726/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي خصائص الليثيوم والكيميائية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3063\n",
            "Semantic Entropy: 0.7997\n",
            "\n",
            "[5727/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الصفات الفيزيائية لليثيوم النقي؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2272\n",
            "Semantic Entropy: 0.6330\n",
            "\n",
            "[5728/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تأثير الماء على الليثيوم؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4222\n",
            "Semantic Entropy: 1.0264\n",
            "\n",
            "[5729/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو أهمية الليثيوم في العلاج الطبي؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4011\n",
            "Semantic Entropy: 0.4611\n",
            "\n",
            "[5730/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي التطبيقات التقنية المهمة لليثيوم؟\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3779\n",
            "Semantic Entropy: 1.2593\n",
            "✓ Saved partial progress after 5730 questions.\n",
            "\n",
            "[5731/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم اكتشاف عنصر الليثيوم؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1229\n",
            "Semantic Entropy: 0.6624\n",
            "\n",
            "[5732/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو الكيميائي الذي اكتشف وجود الليثيوم؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3200\n",
            "Semantic Entropy: 1.3791\n",
            "\n",
            "[5733/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العملية التي استخدمت للحصول على الليثيوم النقي؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0011\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5734/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من كان أول من لاحظ لون اللهب الأحمر الزاهي الناتج عن أملاح الليثيوم؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.4163\n",
            "Semantic Entropy: 2.1220\n",
            "\n",
            "[5735/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو وزن الذري الحقيقي لليثيوم؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1903\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5735 questions.\n",
            "\n",
            "[5736/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العملية التي فتحت الباب للإنتاج التجاري من الليثيوم؟\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4657\n",
            "Semantic Entropy: 1.3377\n",
            "\n",
            "[5737/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو ايدك عن مراتي؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3809\n",
            "Semantic Entropy: 0.2082\n",
            "\n",
            "[5738/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي تم انتاج فيلم ايدك عن مراتي؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.7764\n",
            "Semantic Entropy: 1.4862\n",
            "\n",
            "[5739/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم ابطال الفيلم؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3817\n",
            "Semantic Entropy: 1.4621\n",
            "\n",
            "[5740/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم مخرجين الفيلم ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6786\n",
            "Semantic Entropy: 1.6671\n",
            "✓ Saved partial progress after 5740 questions.\n",
            "\n",
            "[5741/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى سيحدث كسوف حلقي للشمس؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.1187\n",
            "Semantic Entropy: 1.0109\n",
            "\n",
            "[5742/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العوامل التي تجعل الشمس تظهر على شكل حلقة أثناء الكسوف الحلقي؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1882\n",
            "Semantic Entropy: 0.2317\n",
            "\n",
            "[5743/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الفرق بين الكسوف الحلقي والكسوف الجزئي؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2011\n",
            "Semantic Entropy: 1.0846\n",
            "\n",
            "[5744/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تعريف الكسوف الحلقي للشمس؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4466\n",
            "Semantic Entropy: 0.6890\n",
            "\n",
            "[5745/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم يستغرق الدورة الكاملة لحدوث الكسوف الحلقي للشمس؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.1176\n",
            "Semantic Entropy: 0.5469\n",
            "✓ Saved partial progress after 5745 questions.\n",
            "\n",
            "[5746/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم مبتكرين الشخصية؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5130\n",
            "Semantic Entropy: 0.5140\n",
            "\n",
            "[5747/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو أدميرال أكبر؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4877\n",
            "Semantic Entropy: 0.8620\n",
            "\n",
            "[5748/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي زانادو (Xanadu)؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5033\n",
            "Semantic Entropy: 2.1388\n",
            "\n",
            "[5749/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تأسست أسرة يوان؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2215\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5750/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تمت إضافة زانادو إلى قائمة التراث الثقافي العالمي لليونسكو؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4655\n",
            "Semantic Entropy: 1.3809\n",
            "✓ Saved partial progress after 5750 questions.\n",
            "\n",
            "[5751/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي منطقة إدارية تقع زانادو؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.6296\n",
            "Semantic Entropy: 0.8730\n",
            "\n",
            "[5752/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو رمز زانادو ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6195\n",
            "Semantic Entropy: 1.1793\n",
            "\n",
            "[5753/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'الي ماذا يشير رمز زانادو ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.6787\n",
            "Semantic Entropy: 0.9504\n",
            "\n",
            "[5754/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي القصيدة التي صنعها صموئيل تايلور كوليردج عن زانادو؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5550\n",
            "Semantic Entropy: 1.0766\n",
            "\n",
            "[5755/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو إليشا أووسو؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2711\n",
            "Semantic Entropy: 1.2315\n",
            "✓ Saved partial progress after 5755 questions.\n",
            "\n",
            "[5756/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي جنسية إليشا أووسو؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3351\n",
            "Semantic Entropy: 1.8343\n",
            "\n",
            "[5757/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز اللاعب إليشا أووسو؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3649\n",
            "Semantic Entropy: 1.6391\n",
            "\n",
            "[5758/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد إليشا أووسو؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.7543\n",
            "Semantic Entropy: 1.9085\n",
            "\n",
            "[5759/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد إليشا أووسو؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4578\n",
            "Semantic Entropy: 1.1704\n",
            "\n",
            "[5760/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو النادي الذي لعب معه إليشا أووسو؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2962\n",
            "Semantic Entropy: 1.0319\n",
            "✓ Saved partial progress after 5760 questions.\n",
            "\n",
            "[5761/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو كمال أحمد؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3175\n",
            "Semantic Entropy: 0.5401\n",
            "\n",
            "[5762/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي سنة وُلد كمال أحمد؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3079\n",
            "Semantic Entropy: 0.6416\n",
            "\n",
            "[5763/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الصحيفة التي عمل فيها كمحرر سياسي قبل بي بي سي؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.1372\n",
            "Semantic Entropy: 0.4845\n",
            "\n",
            "[5764/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي وظيفة كمال أحمد في لجنة المساواة وحقوق الإنسان؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0908\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5765/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو زميل الصحفي الذي انتقد مصداقية كمال أحمد؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4593\n",
            "Semantic Entropy: 2.0264\n",
            "✓ Saved partial progress after 5765 questions.\n",
            "\n",
            "[5766/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو منصب كمال أحمد في هيئة الإذاعة البريطانية (بي بي سي)؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4276\n",
            "Semantic Entropy: 1.5495\n",
            "\n",
            "[5767/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم تعيين كمال أحمد مديرًا لتحرير بي بي سي نيوز؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3863\n",
            "Semantic Entropy: 0.9163\n",
            "\n",
            "[5768/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي قائمة \"بورليست 2021\"؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.6340\n",
            "Semantic Entropy: 1.9749\n",
            "\n",
            "[5769/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا تمت إقالة كمال أحمد من هيئة الإذاعة البريطانية (بي بي سي)؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5949\n",
            "Semantic Entropy: 1.4992\n",
            "\n",
            "[5770/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الخدمة الإخبارية الرقمية التي أسسها كمال أحمد؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 1.0028\n",
            "Semantic Entropy: 0.8111\n",
            "✓ Saved partial progress after 5770 questions.\n",
            "\n",
            "[5771/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'مع من تزوج كمال أحمد وأنجب منها طفلين؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4638\n",
            "Semantic Entropy: 1.6229\n",
            "\n",
            "[5772/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي ضريبة القيمة المضافة في الاتحاد الأوروبي؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2135\n",
            "Semantic Entropy: 0.2637\n",
            "\n",
            "[5773/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي معدلات ضريبة القيمة المضافة في الدول الأعضاء في الاتحاد الأوروبي في المجر؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0037\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5774/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي معدلات ضريبة القيمة المضافة في الدول الأعضاء في الاتحاد الأوروبي في  كسمبورغ؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0936\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5775/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا يعنى بضريبة المدخلات في ضريبة القيمة المضافة؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2867\n",
            "Semantic Entropy: 1.1405\n",
            "✓ Saved partial progress after 5775 questions.\n",
            "\n",
            "[5776/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا يعنى بضريبة المخرجات في ضريبة القيمة المضافة؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.4488\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5777/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مصطلح الوحدة في التنوع ؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.5446\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5778/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا يعني مصطلح الوحدة في التنوع ؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3309\n",
            "Semantic Entropy: 0.5103\n",
            "\n",
            "[5779/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز اللاعب إلياس أخوماش شكو؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1357\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5780/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين يلعب إلياس أخوماش شكو حاليا؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.7833\n",
            "Semantic Entropy: 1.6414\n",
            "✓ Saved partial progress after 5780 questions.\n",
            "\n",
            "[5781/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي لعب أول مباراة احترافية له مع نادي برشلونة؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6336\n",
            "Semantic Entropy: 1.5840\n",
            "\n",
            "[5782/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي  تم اختياره في التشكيلة الأساسية للفريق الأول لبرشلونة؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.8701\n",
            "Semantic Entropy: 1.7475\n",
            "\n",
            "[5783/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو إلياس أخوماش شكو؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3502\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5784/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد إلياس أخوماش شكو؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.9663\n",
            "Semantic Entropy: 1.9379\n",
            "\n",
            "[5785/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو فيليب لوثار مارينج؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1649\n",
            "Semantic Entropy: 0.2435\n",
            "✓ Saved partial progress after 5785 questions.\n",
            "\n",
            "[5786/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي تاريخ ولد فيليب لوثار مارينج؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.4563\n",
            "Semantic Entropy: 2.2915\n",
            "\n",
            "[5787/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تاريخ وفاة فيليب لوثار مارينج؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.8001\n",
            "Semantic Entropy: 2.1983\n",
            "\n",
            "[5788/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد الأفلام التي عمل فيها فيليب لوثار مارينج على السيناريو؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.7365\n",
            "Semantic Entropy: 1.0210\n",
            "\n",
            "[5789/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الجنسية التي ينتمي إليها فيليب لوثار مارينج؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2678\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5790/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المجالات التي عمل فيها فيليب لوثار مارينج؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2377\n",
            "Semantic Entropy: 1.0025\n",
            "✓ Saved partial progress after 5790 questions.\n",
            "\n",
            "[5791/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '\n",
            "ما هي السمات البيئية المميزة لبلاد الباسك؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3889\n",
            "Semantic Entropy: 1.4473\n",
            "\n",
            "[5792/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي إقليم الباسك وموقعها في إسبانيا؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2275\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5793/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العاصمة الإقليمية لإقليم الباسك ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2125\n",
            "Semantic Entropy: 1.1301\n",
            "\n",
            "[5794/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المقاطعات التي ينقسم إليها؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5593\n",
            "Semantic Entropy: 1.5925\n",
            "\n",
            "[5795/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد البلديات في إقليم الباسك وكم عدد السكان فيها؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4046\n",
            "Semantic Entropy: 1.2971\n",
            "✓ Saved partial progress after 5795 questions.\n",
            "\n",
            "[5796/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الجوائز التي حصلت عليها مدينة بلباو في إقليم الباسك؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3892\n",
            "Semantic Entropy: 1.6144\n",
            "\n",
            "[5797/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو معدل الجريمة في إقليم الباسك؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.4885\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5798/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يقارن بمتوسط الدولة؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5211\n",
            "Semantic Entropy: 1.6467\n",
            "\n",
            "[5799/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المراكز التعليمية الدولية المشهورة في إقليم الباسك؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5611\n",
            "Semantic Entropy: 2.0079\n",
            "\n",
            "[5800/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الحدود الجغرافية لإقليم الباسك؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0873\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5800 questions.\n",
            "\n",
            "[5801/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الحدود الجغرافية لإقليم الباسك يحدها من الشمال ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4335\n",
            "Semantic Entropy: 1.0212\n",
            "\n",
            "[5802/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الحدود الجغرافية لإقليم الباسك يحدها من الجنوب؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4195\n",
            "Semantic Entropy: 0.3964\n",
            "\n",
            "[5803/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الحدود الجغرافية لإقليم الباسك يحدها من الشرق ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2823\n",
            "Semantic Entropy: 0.5024\n",
            "\n",
            "[5804/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الحدود الجغرافية لإقليم الباسك يحدها من الغرب؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.7852\n",
            "Semantic Entropy: 0.1502\n",
            "\n",
            "[5805/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المساحة الإجمالية لإقليم الباسك؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6577\n",
            "Semantic Entropy: 1.0373\n",
            "✓ Saved partial progress after 5805 questions.\n",
            "\n",
            "[5806/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي السمات الجغرافية لإقليم الباسك؟ '\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2392\n",
            "Semantic Entropy: 1.2497\n",
            "\n",
            "[5807/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يكون التنظيم السياسي في إقليم الباسك؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3657\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5808/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتم تنظيم العلاقات المالية والضرائبية بين بلاد الباسك والدولة الإسبانية؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5001\n",
            "Semantic Entropy: 1.0082\n",
            "\n",
            "[5809/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مستوى الاستقلالية الذاتية لإقليم الباسك؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2441\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5810/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي نسبة المديونية للناتج الداخلي الإجمالي في إقليم الباسك؟ '\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.6900\n",
            "Semantic Entropy: 0.5028\n",
            "✓ Saved partial progress after 5810 questions.\n",
            "\n",
            "[5811/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يقارن ذلك بالمتوسط الوطني؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3649\n",
            "Semantic Entropy: 0.5602\n",
            "\n",
            "[5812/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو مؤلف كتاب التفسير الشيعي \"راهنما\"؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.2720\n",
            "Semantic Entropy: 1.2230\n",
            "\n",
            "[5813/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد المجلدات التي تم نشرها من كتاب \"راهنما\"؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2560\n",
            "Semantic Entropy: 1.1415\n",
            "\n",
            "[5814/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي سجن قضى أكبر هاشمي رفسنجاني 3 سنوات قبل الثورة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4259\n",
            "Semantic Entropy: 1.4021\n",
            "\n",
            "[5815/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد المذكرات التي كتبها أكبر هاشمي رفسنجاني حول فهمه للقرآن خلال فترة سجنه؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.6964\n",
            "Semantic Entropy: 1.2168\n",
            "✓ Saved partial progress after 5815 questions.\n",
            "\n",
            "[5816/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم نشر المجلد الأول من كتاب \"راهنما\"؟\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.1471\n",
            "Semantic Entropy: 1.6060\n",
            "\n",
            "[5817/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو أمين العاصمة بغداد؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4286\n",
            "Semantic Entropy: 1.2719\n",
            "\n",
            "[5818/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي مهام أمين العاصمة بغداد؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5813\n",
            "Semantic Entropy: 0.4762\n",
            "\n",
            "[5819/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو التاريخ الذي تحوّلت فيه بغداد من بلدية إلى أمانة؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0028\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5820/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من أول من شغل منصب أمين العاصمة بغداد؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6184\n",
            "Semantic Entropy: 0.7147\n",
            "✓ Saved partial progress after 5820 questions.\n",
            "\n",
            "[5821/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم ارتباط منصب أمين بغداد بمجلس الوزراء العراقي؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5158\n",
            "Semantic Entropy: 0.9137\n",
            "\n",
            "[5822/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو منصب أمين بغداد؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4236\n",
            "Semantic Entropy: 0.8909\n",
            "\n",
            "[5823/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هودرجة  أمين بغداد ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4707\n",
            "Semantic Entropy: 1.4951\n",
            "\n",
            "[5824/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو التحبيب السام؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5439\n",
            "Semantic Entropy: 0.5902\n",
            "\n",
            "[5825/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي حبيبات التحبيب السام وأين توجد في الجسم؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3315\n",
            "Semantic Entropy: 1.6110\n",
            "✓ Saved partial progress after 5825 questions.\n",
            "\n",
            "[5826/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الحالات السريرية التي ترتبط بالتحبيب السام؟\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 0.8399\n",
            "Semantic Entropy: 2.2391\n",
            "\n",
            "[5827/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يمكن اكتشاف التحبيب السام في فحص فِلْمُ الدَّمِ المحيطي؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5324\n",
            "Semantic Entropy: 1.2564\n",
            "\n",
            "[5828/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية العلاج الكيمائي في معالجة المرضى الذين يعانون من التحبيب السام؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5681\n",
            "Semantic Entropy: 0.6252\n",
            "\n",
            "[5829/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تكوينات الحبيبات السمية وما دورها في هذه الحالة؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.6944\n",
            "Semantic Entropy: 2.1531\n",
            "\n",
            "[5830/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الاختلافات بين الحبيبات الناضجة والحبيبات الأولية في العدلات؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0429\n",
            "Semantic Entropy: -0.0000\n",
            "✓ Saved partial progress after 5830 questions.\n",
            "\n",
            "[5831/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى بدأت جائحة فيروس كورونا ؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3487\n",
            "Semantic Entropy: 0.8352\n",
            "\n",
            "[5832/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مركز اللاعب علي ضاهر؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4813\n",
            "Semantic Entropy: 1.0336\n",
            "\n",
            "[5833/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد علي ضاهر؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5707\n",
            "Semantic Entropy: 2.1284\n",
            "\n",
            "[5834/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'اين ولد علي ضاهر؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3750\n",
            "Semantic Entropy: 0.8022\n",
            "\n",
            "[5835/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي نادي لعب علي ضاهر؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.7343\n",
            "Semantic Entropy: 0.7421\n",
            "✓ Saved partial progress after 5835 questions.\n",
            "\n",
            "[5836/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو علي ضاهر؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4444\n",
            "Semantic Entropy: 1.8743\n",
            "\n",
            "[5837/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم إطلاق قناة الساحل الفضائية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2691\n",
            "Semantic Entropy: 0.9169\n",
            "\n",
            "[5838/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' من هو المسؤول عن إدارة قناة الساحل الفضائية؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6146\n",
            "Semantic Entropy: 1.0299\n",
            "\n",
            "[5839/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' بالإضافة إلى اللغة العربية والفرنسية، ما هي اللغات الوطنية التي تبث بها القناة؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6320\n",
            "Semantic Entropy: 1.7801\n",
            "\n",
            "[5840/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد الموظفين الذين يعملون في قناة الساحل الفضائية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4599\n",
            "Semantic Entropy: 0.4452\n",
            "✓ Saved partial progress after 5840 questions.\n",
            "\n",
            "[5841/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' ما هو السبب وراء توقف بث قناة الساحل الفضائية في بعض الأحيان؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2712\n",
            "Semantic Entropy: 0.4773\n",
            "\n",
            "[5842/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو ساروس 147؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4116\n",
            "Semantic Entropy: 1.2316\n",
            "\n",
            "[5843/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي سيحدث كسوف حلقي للشمس في 2057؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.2232\n",
            "Semantic Entropy: 1.4203\n",
            "\n",
            "[5844/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو  كسوف الشمس؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2594\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5845/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو  الكسوف الحلقي للشمس؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2220\n",
            "Semantic Entropy: 0.2699\n",
            "✓ Saved partial progress after 5845 questions.\n",
            "\n",
            "[5846/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين  يظهر الخسوف الحلقي على شكل كسوف جزئي؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4172\n",
            "Semantic Entropy: 1.0077\n",
            "\n",
            "[5847/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المدى الزمني لسلسلة كسوف الشمس 2054-2058؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5215\n",
            "Semantic Entropy: 1.0441\n",
            "\n",
            "[5848/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد الأحداث في ساروس 147؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6153\n",
            "Semantic Entropy: 1.1437\n",
            "\n",
            "[5849/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى سيحدث أطول كسوف حلقي في القرن الثالث والعشرين؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.1193\n",
            "Semantic Entropy: 1.5695\n",
            "\n",
            "[5850/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تأسس نادي الزمالك؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2265\n",
            "Semantic Entropy: 0.4284\n",
            "✓ Saved partial progress after 5850 questions.\n",
            "\n",
            "[5851/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد المواسم التي شارك فيها نادي الزمالك في الدوري المصري الممتاز حتى موسم 2021-22؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.7881\n",
            "Semantic Entropy: 1.1521\n",
            "\n",
            "[5852/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو اسم البطولة التي أُقيمت خلال الموسم الرياضي 2022-23 وشارك فيها نادي الزمالك؟\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1914\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5853/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم إعلان التشكيلة الأساسية لفريق الزمالك في مباراة كأس السوبر المصري لموسم 2022-23؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4521\n",
            "Semantic Entropy: 1.8175\n",
            "\n",
            "[5854/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو القديس تشارلز لوانجا ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5198\n",
            "Semantic Entropy: 1.6146\n",
            "\n",
            "[5855/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد القديس تشارلز لوانجا ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.1758\n",
            "Semantic Entropy: 0.7151\n",
            "✓ Saved partial progress after 5855 questions.\n",
            "\n",
            "[5856/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي توفي القديس تشارلز لوانجا ؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.9456\n",
            "Semantic Entropy: 2.0004\n",
            "\n",
            "[5857/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد القديس تشارلز لوانجا ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.1557\n",
            "Semantic Entropy: 0.6992\n",
            "\n",
            "[5858/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي تم تقديس تشارلز لوانجا ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4749\n",
            "Semantic Entropy: 1.4749\n",
            "\n",
            "[5859/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'علي يد من تم تقديس تشارلز لوانجا ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4618\n",
            "Semantic Entropy: 1.3756\n",
            "\n",
            "[5860/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو التعريف العام للإشباع؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.5426\n",
            "Semantic Entropy: 0.4597\n",
            "✓ Saved partial progress after 5860 questions.\n",
            "\n",
            "[5861/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المصادر التي ينبع منها الإشباع؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4558\n",
            "Semantic Entropy: 1.6650\n",
            "\n",
            "[5862/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما الدور الذي يلعبه الإشباع في النظم الاجتماعية؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3604\n",
            "Semantic Entropy: 0.4952\n",
            "\n",
            "[5863/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أحد الأمثلة على شعور الإشباع؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3698\n",
            "Semantic Entropy: 0.6926\n",
            "\n",
            "[5864/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المقصود بالإشباع الفوري؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.6305\n",
            "Semantic Entropy: 0.9314\n",
            "\n",
            "[5865/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفضيلة المرتبطة بالإشباع المؤجل؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2541\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5865 questions.\n",
            "\n",
            "[5866/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هي الشركة التي قامت بتطوير تطبيق Freemake Video Converter؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5585\n",
            "Semantic Entropy: 1.9092\n",
            "\n",
            "[5867/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي استخدامات برنامج Freemake Video Converter؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3245\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5868/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الميزات الأساسية التي يمكن للمستخدمين استخدامها في النسخة المجانية من Freemake Video Converter؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4916\n",
            "Semantic Entropy: 1.3053\n",
            "\n",
            "[5869/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأجهزة التي يمكن لـ Freemake Video Converter دعمها فيما يتعلق بتحويل وتشغيل مقاطع الفيديو؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2903\n",
            "Semantic Entropy: 0.2733\n",
            "\n",
            "[5870/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'هل يمكن لـ Freemake Video Converter إنشاء عروض شرائح للصور مع موسيقى خلفية؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1341\n",
            "Semantic Entropy: 0.2282\n",
            "✓ Saved partial progress after 5870 questions.\n",
            "\n",
            "[5871/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تعريف الحضارة ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3613\n",
            "Semantic Entropy: 1.4922\n",
            "\n",
            "[5872/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية الحوافز الطبيعية في تحفيز الإنسان على الإبداع والإنشاء؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.5928\n",
            "Semantic Entropy: 2.0068\n",
            "\n",
            "[5873/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف ترتكز الحضارة على البحث العلمي والفني التشكيلي؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2896\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5874/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو معنى الكلمة \"حضارة\" في اللغة العربية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5698\n",
            "Semantic Entropy: 1.2667\n",
            "\n",
            "[5875/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الفروق بين المجتمعات الحضرية والبدوية؟\n",
            ".'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2757\n",
            "Semantic Entropy: 0.6117\n",
            "✓ Saved partial progress after 5875 questions.\n",
            "\n",
            "[5876/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تعريف الحضارة كأسلوب معيشي؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.5051\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5877/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العناصر التي تدرس للتعرف على حضارات الشعوب؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.5975\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5878/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي منطقة ماكاو الإدارية الخاصة؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2139\n",
            "Semantic Entropy: 0.8481\n",
            "\n",
            "[5879/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا تجذب ماكاو السائحين؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3510\n",
            "Semantic Entropy: 0.6288\n",
            "\n",
            "[5880/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو حجم منطقة ماكاو الإدارية الخاصة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.3180\n",
            "Semantic Entropy: 1.6793\n",
            "✓ Saved partial progress after 5880 questions.\n",
            "\n",
            "[5881/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي عهد كانت تتبع ماكاو منطقة نانهاي؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2959\n",
            "Semantic Entropy: 1.0994\n",
            "\n",
            "[5882/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' ما هو مصطلح \"دانوي\" في الصين؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.8795\n",
            "Semantic Entropy: 1.9824\n",
            "\n",
            "[5883/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى بدأت الصين في تقليل تأثير وحدات العمل (دانوي)؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5085\n",
            "Semantic Entropy: 1.0941\n",
            "\n",
            "[5884/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأوضاع التي أدت إلى تقليل تأثير وحدات العمل (دانوي)؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3419\n",
            "Semantic Entropy: 1.0780\n",
            "\n",
            "[5885/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي تمت تقليل الكثير من صلاحيات وتاثير وحدات العمل (دانوي)؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.6055\n",
            "Semantic Entropy: 2.1008\n",
            "✓ Saved partial progress after 5885 questions.\n",
            "\n",
            "[5886/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي طورت دولة الحزب نظام دانوي لتنظيم المناطق الحضرية والسيطرة عليها؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5124\n",
            "Semantic Entropy: 1.1022\n",
            "\n",
            "[5887/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو موزيلا فايرفوكس؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2085\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5888/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '\n",
            "من يطور متصفح فايرفوكس؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5098\n",
            "Semantic Entropy: 1.1277\n",
            "\n",
            "[5889/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو محرك تخطيط جيكو؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6396\n",
            "Semantic Entropy: 1.1611\n",
            "\n",
            "[5890/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'على أي نظام تشغيل يمكن استخدام فايرفوكس رسميًا؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3213\n",
            "Semantic Entropy: 0.8000\n",
            "✓ Saved partial progress after 5890 questions.\n",
            "\n",
            "[5891/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو الاختلاف بين فايرفوكس وإنترنت إكسبلورر؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5212\n",
            "Semantic Entropy: 1.2614\n",
            "\n",
            "[5892/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: '\n",
            "ما هو مجتمع موزيلا؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3692\n",
            "Semantic Entropy: 0.5677\n",
            "\n",
            "[5893/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من بدأ مشروع فايرفوكس؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1531\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5894/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' وما هي تقنية كوانتوم؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4296\n",
            "Semantic Entropy: 1.8669\n",
            "\n",
            "[5895/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأسماء التي كان يعرف بها فايرفوكس في السابق؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5659\n",
            "Semantic Entropy: 2.1585\n",
            "✓ Saved partial progress after 5895 questions.\n",
            "\n",
            "[5896/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي بعض الميزات الشائعة في فايرفوكس؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0071\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5897/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو اختصار فايرفوكس؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3382\n",
            "Semantic Entropy: 0.3461\n",
            "\n",
            "[5898/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي التغييرات التي طرأت على مشروع فايرفوكس قبل الإصدار 1.0؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.8153\n",
            "Semantic Entropy: 1.9289\n",
            "\n",
            "[5899/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف تم تحديد اسم فايرفوكس؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.8377\n",
            "Semantic Entropy: 1.6032\n",
            "\n",
            "[5900/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأسباب التي دفعت فريق فايرفوكس لإنشاء متصفح مستقل؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5834\n",
            "Semantic Entropy: 1.6010\n",
            "✓ Saved partial progress after 5900 questions.\n",
            "\n",
            "[5901/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الميزة التي كانت الأولى في فايرفوكس وقد تبنتها متصفحات أخرى في وقت لاحق؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.9003\n",
            "Semantic Entropy: 1.5827\n",
            "\n",
            "[5902/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الشركة المسؤولة عن تطوير فايرفوكس؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2899\n",
            "Semantic Entropy: 0.5136\n",
            "\n",
            "[5903/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تاريخ إطلاق أول إصدار لمتصفح فايرفوكس؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4661\n",
            "Semantic Entropy: 1.8342\n",
            "\n",
            "[5904/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو حل موزيلا لمشكلة تعطيل جميع إضافات المتصفح في فايرفوكس؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4401\n",
            "Semantic Entropy: 1.3493\n",
            "\n",
            "[5905/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما الذي تسبب في تعطيل جميع إضافات المتصفح في فايرفوكس في 3 مايو 2019؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.5799\n",
            "Semantic Entropy: 1.1065\n",
            "✓ Saved partial progress after 5905 questions.\n",
            "\n",
            "[5906/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الشاب لهذا ؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.7932\n",
            "Semantic Entropy: 1.8800\n",
            "\n",
            "[5907/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي تم عرض الحلقة؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4456\n",
            "Semantic Entropy: 0.9653\n",
            "\n",
            "[5908/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'علي أي قناة عرضت الحلقة داخل الولايات المتحدة؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3284\n",
            "Semantic Entropy: 0.2375\n",
            "\n",
            "[5909/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المسلسل الذي أقتبس منه هذا المسلسل؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5523\n",
            "Semantic Entropy: 1.8121\n",
            "\n",
            "[5910/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي محافظة شيغا؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.2321\n",
            "Semantic Entropy: 0.8595\n",
            "✓ Saved partial progress after 5910 questions.\n",
            "\n",
            "[5911/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي منطقة من اليابان تقع محافظة شيغا؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.0019\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5912/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي عاصمة محافظة شيغا؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1544\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5913/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد المدن التي تضمها محافظة شيغا؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4868\n",
            "Semantic Entropy: 1.1995\n",
            "\n",
            "[5914/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأندية الرياضية الموجودة في محافظة شيغا؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5596\n",
            "Semantic Entropy: 1.4939\n",
            "\n",
            "[5915/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو رودريغو ماركيز دي سانتانا؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2186\n",
            "Semantic Entropy: 0.6258\n",
            "✓ Saved partial progress after 5915 questions.\n",
            "\n",
            "[5916/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو موقع ميلاد رودريغو ماركيز دي سانتانا؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2617\n",
            "Semantic Entropy: 0.7474\n",
            "\n",
            "[5917/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي مركز يلعب رودريغو ماركيز دي سانتانا في كرة القدم؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3772\n",
            "Semantic Entropy: 0.3690\n",
            "\n",
            "[5918/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تاريخ ميلاد رودريغو ماركيز دي سانتانا؟\n",
            "\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 10 semantic clusters\n",
            " naive Entropy: 1.3113\n",
            "Semantic Entropy: 2.1220\n",
            "\n",
            "[5919/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو جورج صباغ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3563\n",
            "Semantic Entropy: 0.7109\n",
            "\n",
            "[5920/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد جورج صباغ؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.1876\n",
            "Semantic Entropy: 0.4215\n",
            "✓ Saved partial progress after 5920 questions.\n",
            "\n",
            "[5921/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أصول جورج صباغ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5392\n",
            "Semantic Entropy: 1.4267\n",
            "\n",
            "[5922/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' أين درس جورج صباغ؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3042\n",
            "Semantic Entropy: 0.6930\n",
            "\n",
            "[5923/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى توجه جورج صباغ إلى باريس؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.3746\n",
            "Semantic Entropy: 1.9780\n",
            "\n",
            "[5924/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا توجه جورج صباغ الي باريس و أين سكن هناك ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5647\n",
            "Semantic Entropy: 1.8374\n",
            "\n",
            "[5925/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا احترف جورج صباغ في باريس؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4720\n",
            "Semantic Entropy: 0.5483\n",
            "✓ Saved partial progress after 5925 questions.\n",
            "\n",
            "[5926/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي توفي جورج صباغ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.2401\n",
            "Semantic Entropy: 1.4573\n",
            "\n",
            "[5927/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تصنيف فيلم تعليم أوما أوباما ؟'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 1.0196\n",
            "Semantic Entropy: 0.6919\n",
            "\n",
            "[5928/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي صدر فيلم تعليم أوما أوباما ؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.9518\n",
            "Semantic Entropy: 1.4570\n",
            "\n",
            "[5929/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الشخصية التي يدور حولها الفيلم ؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.6253\n",
            "Semantic Entropy: 2.0498\n",
            "\n",
            "[5930/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' ما هي الجائزة التي فاز بها الفيلم؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2784\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5930 questions.\n",
            "\n",
            "[5931/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي قصة غنجي؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.4698\n",
            "Semantic Entropy: 1.8218\n",
            "\n",
            "[5932/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو صاحب قصة غنجي؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.2557\n",
            "Semantic Entropy: 0.9032\n",
            "\n",
            "[5933/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي احداث قصه غنجي ؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5839\n",
            "Semantic Entropy: 2.1225\n",
            "\n",
            "[5934/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من اي عائله ينتمي الشخص ف  غنجي ؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3425\n",
            "Semantic Entropy: 1.0330\n",
            "\n",
            "[5935/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عمر قصه غنجي ؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.6141\n",
            "Semantic Entropy: 1.8374\n",
            "✓ Saved partial progress after 5935 questions.\n",
            "\n",
            "[5936/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو حمد بن خليفة بن حمد بن عبد الله بن جاسم بن محمد بن ثاني؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3117\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5937/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف تولى حمد بن خليفة الإمارة في قطر؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.4555\n",
            "Semantic Entropy: 0.6153\n",
            "\n",
            "[5938/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين تلقى حمد بن خليفة دراسته الابتدائية والثانوية؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.6980\n",
            "Semantic Entropy: 1.4250\n",
            "\n",
            "[5939/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأكاديمية التي التحق بها حمد بن خليفة في المملكة المتحدة؟'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3787\n",
            "Semantic Entropy: 0.4296\n",
            "\n",
            "[5940/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الدور العسكري الذي لعبه حمد بن خليفة في القوات المسلحة القطرية؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4160\n",
            "Semantic Entropy: 0.5983\n",
            "✓ Saved partial progress after 5940 questions.\n",
            "\n",
            "[5941/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الإنجازات التي حققها حمد بن خليفة في تطوير القوات المسلحة القطرية؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.7469\n",
            "Semantic Entropy: 1.9383\n",
            "\n",
            "[5942/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أبرز الإجراءات التي اتخذتها قطر بعد إقرار دستورها الدائم؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5158\n",
            "Semantic Entropy: 1.6058\n",
            "\n",
            "[5943/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور الصحافة والإعلام وحرية التعبير في قطر بعد إلغاء وزارة الإعلام؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4810\n",
            "Semantic Entropy: 1.6527\n",
            "\n",
            "[5944/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الانتخابات التي أجريت في قطر بعد إقرار الدستور الدائم؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4421\n",
            "Semantic Entropy: 0.6656\n",
            "\n",
            "[5945/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف ساهم الأمير في تطور قطر في مجالات العمران والاقتصاد والعلوم والرياضة؟'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5956\n",
            "Semantic Entropy: 1.5065\n",
            "✓ Saved partial progress after 5945 questions.\n",
            "\n",
            "[5946/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الانتقادات التي واجهها الأمير بخصوص سحب جوازات المواطنين ودعوى ازدواجية جنسيتهم؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1803\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5947/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العلاقات الدولية التي وثقها الأمير مع دول العالم؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2646\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5948/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تفاصيل اللقاء الذي جمع الأمير بوزير خارجية إسرائيل في سبتمبر 2007م؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4760\n",
            "Semantic Entropy: 0.6639\n",
            "\n",
            "[5949/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا قطعت قطر العلاقات الدبلوماسية مع إسرائيل في عام 2009م؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2198\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5950/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المنظمات التي يستخدم أفرادها طريقًا معينًا لتحقيق أهدافها؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2941\n",
            "Semantic Entropy: 0.1677\n",
            "✓ Saved partial progress after 5950 questions.\n",
            "\n",
            "[5951/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الجهات التي تدير المنظمات، وكيف يتم انتخابها؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3273\n",
            "Semantic Entropy: 0.9377\n",
            "\n",
            "[5952/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي مهام وأهداف المنظمات غير الحكومية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.6327\n",
            "Semantic Entropy: 0.9369\n",
            "\n",
            "[5953/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتم تنظيم المنظمات غير الحكومية؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.5959\n",
            "Semantic Entropy: 1.3474\n",
            "\n",
            "[5954/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأنشطة والبرامج التي تتعلق بالقضايا التي تهم الأمم المتحدة التي تقوم بها المنظمات غير الحكومية؟\n",
            "\n",
            "\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.5353\n",
            "Semantic Entropy: 0.3704\n",
            "\n",
            "[5955/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو تعريف المنظمة كشخصية اعتبارية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3352\n",
            "Semantic Entropy: 0.6273\n",
            "✓ Saved partial progress after 5955 questions.\n",
            "\n",
            "[5956/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو دور إدارة شؤون الإعلام في المنظمات غير الحكومية؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4590\n",
            "Semantic Entropy: 1.2688\n",
            "\n",
            "[5957/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي أهمية المنظمات غير الحكومية في العالم الحالي؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.5156\n",
            "Semantic Entropy: 1.8666\n",
            "\n",
            "[5958/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي المنظمات غير الحكومية؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4491\n",
            "Semantic Entropy: 0.7611\n",
            "\n",
            "[5959/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العلاقة بين المنظمات غير الحكومية ومنظومة الأمم المتحدة؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3640\n",
            "Semantic Entropy: 1.0866\n",
            "\n",
            "[5960/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم عدد المنظمات غير الحكومية في العالم؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4097\n",
            "Semantic Entropy: 0.7848\n",
            "✓ Saved partial progress after 5960 questions.\n",
            "\n",
            "[5961/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو \"متعددات الحدود للوجوندر\"؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4787\n",
            "Semantic Entropy: 0.6004\n",
            "\n",
            "[5962/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا سُميت متعددات الحدود للوجوندر بهذا الاسم؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2966\n",
            "Semantic Entropy: 0.5249\n",
            "\n",
            "[5963/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الخصائص الرياضياتية لمتعددات الحدود للوجوندر؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5748\n",
            "Semantic Entropy: 1.7071\n",
            "\n",
            "[5964/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هو كارل سيرانت؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4375\n",
            "Semantic Entropy: 1.4881\n",
            "\n",
            "[5965/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متي ولد كارل سيرانت؟'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.4782\n",
            "Semantic Entropy: 1.4877\n",
            "✓ Saved partial progress after 5965 questions.\n",
            "\n",
            "[5966/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو المنصب الحالي لكارل سيرانت؟'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.6039\n",
            "Semantic Entropy: 1.9088\n",
            "\n",
            "[5967/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'أين ولد كارل سيرانت؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5780\n",
            "Semantic Entropy: 0.7578\n",
            "\n",
            "[5968/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كم مبارة خاضها كارل سيرانت؟'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.3976\n",
            "Semantic Entropy: 2.1203\n",
            "\n",
            "[5969/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'لماذا انقطعت مسيرته الأحترافيه؟'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5620\n",
            "Semantic Entropy: 0.8220\n",
            "\n",
            "[5970/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي تعريفة إدارة الفنون؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.5526\n",
            "Semantic Entropy: 0.9165\n",
            "✓ Saved partial progress after 5970 questions.\n",
            "\n",
            "[5971/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الكيانات التي تشملها إدارة الفنون؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.4373\n",
            "Semantic Entropy: 0.9732\n",
            "\n",
            "[5972/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي بعض المهام التي يقوم بها مديرو الفنون؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.6753\n",
            "Semantic Entropy: 0.2982\n",
            "\n",
            "[5973/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي مسؤوليات مدير الفنون؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.7570\n",
            "Semantic Entropy: 0.5694\n",
            "\n",
            "[5974/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'في أي نوع من المنظمات يعمل مديرو الفنون؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2311\n",
            "Semantic Entropy: -0.0000\n",
            "\n",
            "[5975/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الجوانب التي يشملها دور مدير الفنون في التسويق؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4031\n",
            "Semantic Entropy: 1.3596\n",
            "✓ Saved partial progress after 5975 questions.\n",
            "\n",
            "[5976/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي العلاقة بين مدير الفنون ومجلس الإدارة؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.3511\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5977/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأهداف الرئيسية التي يسعى مديرو الفنون لتحقيقها؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6456\n",
            "Semantic Entropy: 1.7075\n",
            "\n",
            "[5978/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأنشطة التي يشرف عليها مديرو الفنون في المؤسسات الثقافية؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.3526\n",
            "Semantic Entropy: 0.2322\n",
            "\n",
            "[5979/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأنشطة التي تدخل في مجال تطوير البرامج لدى مديرو الفنون؟\n",
            "\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.6783\n",
            "Semantic Entropy: 1.2917\n",
            "\n",
            "[5980/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي طريقة الاندماج الخطي للمدارات الذرية والمدارات الجزيئية'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.3797\n",
            "Semantic Entropy: 1.0989\n",
            "✓ Saved partial progress after 5980 questions.\n",
            "\n",
            "[5981/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي التقنية المستخدمة في الفيزياء الجزيئية لحساب المدارات الجزيئية في كيمياء الكم؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.5182\n",
            "Semantic Entropy: 1.6369\n",
            "\n",
            "[5982/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم العلماء الذين بدأوا بفكرة الاندماج الخطي للمدارات الجزيئية '\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.9412\n",
            "Semantic Entropy: 2.0723\n",
            "\n",
            "[5983/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى بدأوا في ذلك؟\n",
            "'\n",
            "Generated 10 answers in 8 semantic clusters\n",
            " naive Entropy: 0.4358\n",
            "Semantic Entropy: 2.0075\n",
            "\n",
            "[5984/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الدوال الأساسية التي يتم استخدامها في تعبير المدارات الجزيئية؟\n",
            "'\n",
            "Generated 10 answers in 9 semantic clusters\n",
            " naive Entropy: 0.5535\n",
            "Semantic Entropy: 2.1060\n",
            "\n",
            "[5985/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا يعني تقليل الطاقة وتعيين مجموعة ملائمة من المعاملات للاندماج الخطي؟\n",
            "'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.3806\n",
            "Semantic Entropy: 1.6463\n",
            "✓ Saved partial progress after 5985 questions.\n",
            "\n",
            "[5986/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتم استغلال التشابه في الجزيئات والمدارات المتضمنة في الروابط؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3857\n",
            "Semantic Entropy: 0.9968\n",
            "\n",
            "[5987/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الخطوة الأولى في عملية التعبير عن المدارات الجزيئية بطريقة الاندماج الخطي؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.5396\n",
            "Semantic Entropy: 0.3753\n",
            "\n",
            "[5988/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو مثال عام للجزيء الذي يتم تعبيره بواسطة مجموعة نقطية وتم تقليل تمثيل الترابط؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.3652\n",
            "Semantic Entropy: 0.9315\n",
            "\n",
            "[5989/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ماذا يعني عدد الروابط التي لم يتم تحريكها في تعبير المدارات الجزيئية؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.2660\n",
            "Semantic Entropy: 0.2421\n",
            "\n",
            "[5990/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: ' ما هي لعبة توربو غولف ريسينغ؟'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.2919\n",
            "Semantic Entropy: 0.0000\n",
            "✓ Saved partial progress after 5990 questions.\n",
            "\n",
            "[5991/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى تم إصدار النسخة الأولية من توربو غولف ريسينغ؟\n",
            "'\n",
            "Generated 10 answers in 2 semantic clusters\n",
            " naive Entropy: 0.1142\n",
            "Semantic Entropy: 0.3111\n",
            "\n",
            "[5992/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'على أي منصات يمكن لعب توربو غولف ريسينغ؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1002\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5993/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'متى بدأ انتشار فيروس غرب النيل في الولايات المتحدة؟\n",
            "'\n",
            "Generated 10 answers in 1 semantic clusters\n",
            " naive Entropy: 0.1783\n",
            "Semantic Entropy: 0.0000\n",
            "\n",
            "[5994/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الأنواع الأخرى التي ظهر فيها فيروس غرب النيل؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4731\n",
            "Semantic Entropy: 1.1764\n",
            "\n",
            "[5995/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو عدد الحالات والوفيات السنوية الناجمة عن فيروس غرب النيل في الولايات المتحدة؟\n",
            "'\n",
            "Generated 10 answers in 6 semantic clusters\n",
            " naive Entropy: 0.6588\n",
            "Semantic Entropy: 1.6654\n",
            "✓ Saved partial progress after 5995 questions.\n",
            "\n",
            "[5996/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من هم الأشخاص الأكثر عرضة للإصابة بأمراض خطيرة أو الوفاة بسبب فيروس غرب النيل؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.4408\n",
            "Semantic Entropy: 0.7681\n",
            "\n",
            "[5997/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'كيف يتم تتبع الحالات البشرية المصابة بفيروس غرب النيل؟\n",
            "'\n",
            "Generated 10 answers in 5 semantic clusters\n",
            " naive Entropy: 0.4136\n",
            "Semantic Entropy: 1.4045\n",
            "\n",
            "[5998/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هي الولايات التي تم الإبلاغ فيها عن حالات إصابة بفيروس غرب النيل؟\n",
            "'\n",
            "Generated 10 answers in 3 semantic clusters\n",
            " naive Entropy: 0.3745\n",
            "Semantic Entropy: 0.9044\n",
            "\n",
            "[5999/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'ما هو عدد الإصابات المقدر في الولايات المتحدة خلال الفترة من 1999 إلى 2010؟\n",
            "'\n",
            "Generated 10 answers in 4 semantic clusters\n",
            " naive Entropy: 0.6204\n",
            "Semantic Entropy: 1.1756\n",
            "\n",
            "[6000/6000] Processing question\n",
            "\n",
            "Entropy Analysis for: 'من فاز بسباق طواف لوكسمبورغ 2020؟'\n",
            "Generated 10 answers in 7 semantic clusters\n",
            " naive Entropy: 0.9149\n",
            "Semantic Entropy: 1.5521\n",
            "✓ Saved partial progress after 6000 questions.\n",
            "\n",
            "Saving final results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f09a7ae3-fe89-416b-8d2e-1996d4b54591\", \"semantic_entropy_jais_arabicaqa_results.json\", 11299054)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Experiment completed successfully with jais model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRo1E9seb8tM"
      },
      "source": [
        "# **extra**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht7O3pP9bGFU"
      },
      "outputs": [],
      "source": [
        "files.download(f'semantic_entropy_{MODEL_CHOICE}_{DATASET_CHOICE}_results.json')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOEOGC2OiU7jVVIT0H1CSua",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce2418df4aef43239f305453d71546eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6be7faeff02142a6bc3c1224ebd587bc",
              "IPY_MODEL_0d471c85c1574e18a45a6d2496c12473",
              "IPY_MODEL_d01df6d0899d428e9b12085ffa2f5889"
            ],
            "layout": "IPY_MODEL_d31b67cc11f04738a122b455f368ff5c"
          }
        },
        "6be7faeff02142a6bc3c1224ebd587bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4405a5d32147bc8d8445e3927354dd",
            "placeholder": "​",
            "style": "IPY_MODEL_fd2e427c50164cddafb0fb5e33231d91",
            "value": "configuration_jais.py: 100%"
          }
        },
        "0d471c85c1574e18a45a6d2496c12473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da1a29e69dd41b58ed30b082cb42601",
            "max": 9521,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf89feb992bc43bc9d7a9744f0535f33",
            "value": 9521
          }
        },
        "d01df6d0899d428e9b12085ffa2f5889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e2406fd59b4821bb7ee13d9c4cad27",
            "placeholder": "​",
            "style": "IPY_MODEL_09c2ec0d0d37471db574584234d57c6d",
            "value": " 9.52k/9.52k [00:00&lt;00:00, 1.14MB/s]"
          }
        },
        "d31b67cc11f04738a122b455f368ff5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4405a5d32147bc8d8445e3927354dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2e427c50164cddafb0fb5e33231d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1da1a29e69dd41b58ed30b082cb42601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf89feb992bc43bc9d7a9744f0535f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97e2406fd59b4821bb7ee13d9c4cad27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c2ec0d0d37471db574584234d57c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8563b07aaa4841509a38552a92637d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bef4437379304b3ba100080f13fc4431",
              "IPY_MODEL_31caeb126831429d98be47cc297291d3",
              "IPY_MODEL_f9fff8abe4fe4272bbf9e3577bbecd2f"
            ],
            "layout": "IPY_MODEL_449c30770148419a9767dba429ca3802"
          }
        },
        "bef4437379304b3ba100080f13fc4431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc5972fae8fa41ec933b35554163bd89",
            "placeholder": "​",
            "style": "IPY_MODEL_f01f5ec1fe0048d7bdd4a9184cc04f35",
            "value": "modeling_jais.py: 100%"
          }
        },
        "31caeb126831429d98be47cc297291d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca60a3415da404b9078bd00abd19fe3",
            "max": 71836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc4189b1e19478fb797287ce4bedada",
            "value": 71836
          }
        },
        "f9fff8abe4fe4272bbf9e3577bbecd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c295a76dda74ecfb029399846a4b1e0",
            "placeholder": "​",
            "style": "IPY_MODEL_223fca8cb9b44b55babb67c1e60c086d",
            "value": " 71.8k/71.8k [00:00&lt;00:00, 4.49MB/s]"
          }
        },
        "449c30770148419a9767dba429ca3802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5972fae8fa41ec933b35554163bd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f01f5ec1fe0048d7bdd4a9184cc04f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dca60a3415da404b9078bd00abd19fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc4189b1e19478fb797287ce4bedada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c295a76dda74ecfb029399846a4b1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "223fca8cb9b44b55babb67c1e60c086d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3bec33e82134b34b31e7b9c110701eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0d6d82ba9174cc6b29b03687f071edc",
              "IPY_MODEL_e308e7cb52224688a4d33b7a53a049bf",
              "IPY_MODEL_439ee4b7a6ae44d88b24daf67d156faf"
            ],
            "layout": "IPY_MODEL_3e74ee04472f4580b1246de33796e76d"
          }
        },
        "a0d6d82ba9174cc6b29b03687f071edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d519c15ba3e44d4c9ff2f21acb1f629f",
            "placeholder": "​",
            "style": "IPY_MODEL_85dee41c27674c5e91652806212a38c6",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "e308e7cb52224688a4d33b7a53a049bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5192eeb6b7074132916e18319ba7c2a7",
            "max": 35753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_570064ae5ca84241bb3fcd92150ea75e",
            "value": 35753
          }
        },
        "439ee4b7a6ae44d88b24daf67d156faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c673d0ee7450434b9983de27e2d611ad",
            "placeholder": "​",
            "style": "IPY_MODEL_3b8c5c2914994231973c9b29d8ed0486",
            "value": " 35.8k/35.8k [00:00&lt;00:00, 4.64MB/s]"
          }
        },
        "3e74ee04472f4580b1246de33796e76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d519c15ba3e44d4c9ff2f21acb1f629f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85dee41c27674c5e91652806212a38c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5192eeb6b7074132916e18319ba7c2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570064ae5ca84241bb3fcd92150ea75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c673d0ee7450434b9983de27e2d611ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8c5c2914994231973c9b29d8ed0486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e03014afbb774ef4b242edc2fe1ea67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c8c5c7e77664367ad9740eae294c4b5",
              "IPY_MODEL_0b050627c9f04df3b8f358599da87a41",
              "IPY_MODEL_4bdbc7a403ab4218bc83d6c81425e660"
            ],
            "layout": "IPY_MODEL_fa89d388e9994021a37020d3a7daed84"
          }
        },
        "0c8c5c7e77664367ad9740eae294c4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e8ddc8d73e4f09a8e2f4409ebb2416",
            "placeholder": "​",
            "style": "IPY_MODEL_5b7610131c0a4d899222b9ff0874c273",
            "value": "Fetching 3 files: 100%"
          }
        },
        "0b050627c9f04df3b8f358599da87a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ebb874d69c94a648b7d8309f4742d3a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55952d679fa34d2d978207bb7588d990",
            "value": 3
          }
        },
        "4bdbc7a403ab4218bc83d6c81425e660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e97a552034f340e1a533ef2b7e1c2edd",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f1e6d4b2404a57bc62461c353dd241",
            "value": " 3/3 [01:31&lt;00:00, 91.28s/it]"
          }
        },
        "fa89d388e9994021a37020d3a7daed84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e8ddc8d73e4f09a8e2f4409ebb2416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b7610131c0a4d899222b9ff0874c273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ebb874d69c94a648b7d8309f4742d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55952d679fa34d2d978207bb7588d990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e97a552034f340e1a533ef2b7e1c2edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f1e6d4b2404a57bc62461c353dd241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a635c53a78fc4c1da81c5e59108ad171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f667efc38b354407988dae37228d638c",
              "IPY_MODEL_0fcb10c29b6247eb9c494822e06dcaa2",
              "IPY_MODEL_e777c8be9cdc446795583f4618ce2cd4"
            ],
            "layout": "IPY_MODEL_18dba330a0fc485a889e8daecd36cf04"
          }
        },
        "f667efc38b354407988dae37228d638c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a6d046a6a654b23b35816500b3296ab",
            "placeholder": "​",
            "style": "IPY_MODEL_d57931384d98452bbc059fe760cfef5e",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "0fcb10c29b6247eb9c494822e06dcaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd916ff4bec41539693a412f4557aee",
            "max": 9848746856,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34dff7e43ca54fd3938249ebe11cc864",
            "value": 9848746856
          }
        },
        "e777c8be9cdc446795583f4618ce2cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fcbe0c3063848418aa0e53318433f32",
            "placeholder": "​",
            "style": "IPY_MODEL_d922b0d525054dc3af0154e31e27b853",
            "value": " 9.85G/9.85G [01:20&lt;00:00, 118MB/s]"
          }
        },
        "18dba330a0fc485a889e8daecd36cf04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6d046a6a654b23b35816500b3296ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57931384d98452bbc059fe760cfef5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd916ff4bec41539693a412f4557aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34dff7e43ca54fd3938249ebe11cc864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fcbe0c3063848418aa0e53318433f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d922b0d525054dc3af0154e31e27b853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c4d083597894df79c6fff117e451dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc1a5383d5674bff8199d56721370f8c",
              "IPY_MODEL_a1908a7656544da48d95c0a62eae84f8",
              "IPY_MODEL_30a981a23b3f441986ef1e2930acda86"
            ],
            "layout": "IPY_MODEL_441f7b80c67f47f292d15e05262b2f84"
          }
        },
        "cc1a5383d5674bff8199d56721370f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05cf6bc142644e4aa6c6628de4298184",
            "placeholder": "​",
            "style": "IPY_MODEL_659b4048b198459fa94c2a426561e17e",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "a1908a7656544da48d95c0a62eae84f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ce9d4906684022b461a24134739d56",
            "max": 8823846904,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24569e6bdb26462d8c494023132b1005",
            "value": 8823846904
          }
        },
        "30a981a23b3f441986ef1e2930acda86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4315262cffe54e979021755e1c89058a",
            "placeholder": "​",
            "style": "IPY_MODEL_ec0e8c40f9d946f8a95c3f088f75cffc",
            "value": " 8.82G/8.82G [01:24&lt;00:00, 131MB/s]"
          }
        },
        "441f7b80c67f47f292d15e05262b2f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05cf6bc142644e4aa6c6628de4298184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "659b4048b198459fa94c2a426561e17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ce9d4906684022b461a24134739d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24569e6bdb26462d8c494023132b1005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4315262cffe54e979021755e1c89058a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0e8c40f9d946f8a95c3f088f75cffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e9786c4040a4c91b210cbace1813e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0fec91aec2f4d5786553c084e445c00",
              "IPY_MODEL_b2ff0c55b7c14e4b84570794102eab94",
              "IPY_MODEL_19af40b6718b425192004a274d0d77d1"
            ],
            "layout": "IPY_MODEL_385531e8cdb948eead5752e9d14a22a1"
          }
        },
        "f0fec91aec2f4d5786553c084e445c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70b6b07f3cd74a69a38def26609d8c33",
            "placeholder": "​",
            "style": "IPY_MODEL_d19ab7bcd08e403489facdf3360f3a72",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "b2ff0c55b7c14e4b84570794102eab94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef38aaf37c5a4abcbc51aa83e6c6d471",
            "max": 9898213584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ea40197da814e3e8a9fac3a6bad0620",
            "value": 9898213584
          }
        },
        "19af40b6718b425192004a274d0d77d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06a28799014243f08d72589de0394eea",
            "placeholder": "​",
            "style": "IPY_MODEL_f16efbe3948a40ebaf20df1fdba5b5b9",
            "value": " 9.90G/9.90G [01:31&lt;00:00, 158MB/s]"
          }
        },
        "385531e8cdb948eead5752e9d14a22a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b6b07f3cd74a69a38def26609d8c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19ab7bcd08e403489facdf3360f3a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef38aaf37c5a4abcbc51aa83e6c6d471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea40197da814e3e8a9fac3a6bad0620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06a28799014243f08d72589de0394eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f16efbe3948a40ebaf20df1fdba5b5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78230125567649e3ad827c9e60a2362a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_314dde10390b4983938a23886d67e19d",
              "IPY_MODEL_0d648dde3f6f47fd8ce9ad2693b8efca",
              "IPY_MODEL_46cfae177e2a429798e7545bc33f2139"
            ],
            "layout": "IPY_MODEL_dcb116e807c7403daaf25ae49a1ac316"
          }
        },
        "314dde10390b4983938a23886d67e19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_193a46b30c494b08ba38d5e718d6b6ec",
            "placeholder": "​",
            "style": "IPY_MODEL_ea584059c88a4e8b9d4d034e21edb26d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0d648dde3f6f47fd8ce9ad2693b8efca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830347169df846d0a3d1e93fb38d8222",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42cce5b58d8948b79cf009a3186761fa",
            "value": 3
          }
        },
        "46cfae177e2a429798e7545bc33f2139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab17077251354dbebb3515ec838edddb",
            "placeholder": "​",
            "style": "IPY_MODEL_d34ec4364afb4fbea829b0bfd5b28db7",
            "value": " 3/3 [00:08&lt;00:00,  2.67s/it]"
          }
        },
        "dcb116e807c7403daaf25ae49a1ac316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "193a46b30c494b08ba38d5e718d6b6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea584059c88a4e8b9d4d034e21edb26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "830347169df846d0a3d1e93fb38d8222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42cce5b58d8948b79cf009a3186761fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab17077251354dbebb3515ec838edddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34ec4364afb4fbea829b0bfd5b28db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5989ced8b3cf446b9df3b4612d4cd701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_328f97e11dfe4546b91dd7b6d6ac54b6",
              "IPY_MODEL_0d9ff5d09faa4ca4bbe82c07c7d73a8c",
              "IPY_MODEL_d111dfcdc2c2433b8951df35d77aa4c7"
            ],
            "layout": "IPY_MODEL_ceefda54887844c88bb8ab1b13efdd88"
          }
        },
        "328f97e11dfe4546b91dd7b6d6ac54b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2361ce93814f24bda10c47999e5505",
            "placeholder": "​",
            "style": "IPY_MODEL_1860f0baa5d14accabc32b9d19def362",
            "value": "Processing questions: 100%"
          }
        },
        "0d9ff5d09faa4ca4bbe82c07c7d73a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54b66221fa354fcfba4a8aaaa26c1328",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac5bc92293814d69838aea97d61c45e3",
            "value": 6000
          }
        },
        "d111dfcdc2c2433b8951df35d77aa4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1bba38154947f59bb34d165efba234",
            "placeholder": "​",
            "style": "IPY_MODEL_71327088a77c44c6b98c4d84094b4b6f",
            "value": " 6000/6000 [8:33:48&lt;00:00,  4.87s/it]"
          }
        },
        "ceefda54887844c88bb8ab1b13efdd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b2361ce93814f24bda10c47999e5505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1860f0baa5d14accabc32b9d19def362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54b66221fa354fcfba4a8aaaa26c1328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5bc92293814d69838aea97d61c45e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b1bba38154947f59bb34d165efba234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71327088a77c44c6b98c4d84094b4b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}