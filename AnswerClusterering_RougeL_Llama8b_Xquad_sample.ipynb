{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reemaalt/Detection-of-Hallucination-in-Arabic/blob/main/AnswerClusterering_RougeL_Llama8b_Xquad_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##QA pairs generated using llama8b on xquad"
      ],
      "metadata": {
        "id": "HQN150dXMiVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9txSrMk9Lz_u",
        "outputId": "c55684d8-b677-4cc7-828e-725fe3f529c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzXoAFUu-Zeh",
        "outputId": "69236173-4d28-4299-86e0-872a64a9b6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   question_id                                           question  \\\n",
            "0          320                             ما هو المرفق بالسواكن؟   \n",
            "1         1007     ما الدليل الذي تقدمه الجينات المُتَبَرَّع بها؟   \n",
            "2          605  ماذا حدث في عام 1992 ضمن إجراءٍ على نطاق الممل...   \n",
            "3          425                   متى أحدِثت توجيهية مجلس الأعمال؟   \n",
            "4            4  من سجل أعلى عدد من الاستحواذات للفريق هذا الموسم؟   \n",
            "\n",
            "                                     original_answer  \\\n",
            "0  {'text': ['غلاف التوربين'], 'answer_start': [1...   \n",
            "1  {'text': ['وجود البلاستيدات الخضراء المفقود'],...   \n",
            "2  {'text': ['أصبحت فيه كليات الفنون التطبيقية جا...   \n",
            "3  {'text': ['استشارات الطاقة العمالية في الأعمال...   \n",
            "4    {'text': ['كاوان شورت'], 'answer_start': [216]}   \n",
            "\n",
            "                                   generated_answers  \n",
            "0  [المرفق بالسواكن هو أحد الأوتار التالية للشخص ...  \n",
            "1  [تتضمن الدنا العِرضيّة نطاقات الدنا المُتِبَرِ...  \n",
            "2  [حصل على جائزة نوبل في الآداب وتم إشهار قانون ...  \n",
            "3  [6/ 13/ 1433 هـ, أجرى مجلس الأعمال التوجيهية ع...  \n",
            "4  [ترويس تشيلسي هو لاعب تشيلسي الذي سجل أعلى عدد...  \n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/generated_answers_Llama3.1-8b-xquad.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RougeL"
      ],
      "metadata": {
        "id": "8q_8V1wQMrfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHkXIo9mLAJi",
        "outputId": "212b1fdb-0415-42db-bb71-03819490986a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=34246a4d7ffa60e9b571f07b523f4e3f82f4cb6f4600dc800ca418a2af07523e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from transformers import AutoTokenizer\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Load AraBERT tokenizer\n",
        "model_name = 'aubmindlab/bert-base-arabertv02'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define the scorer, passing in the AraBERT tokenizer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], tokenizer=tokenizer)  # Pass the tokenizer object\n",
        "\n",
        "# Example strings\n",
        "pred_str = 'السلام عليكم كيف حالك'\n",
        "label_str = 'السلام عليكم صديقي كيف حالك'\n",
        "\n",
        "# Calculate ROUGE score directly using the input strings\n",
        "scores = scorer.score(label_str, pred_str)  # Use original strings\n",
        "\n",
        "for key in scores:\n",
        "    print(f'{key}: {scores[key]}')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCtoeBhjPJtL",
        "outputId": "ea49e13d-e786-4670-ff56-5dda01d5c301"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rougeL: Score(precision=1.0, recall=0.8333333333333334, fmeasure=0.9090909090909091)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import AutoTokenizer\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Load AraBERT tokenizer\n",
        "model_name = 'aubmindlab/bert-base-arabertv02'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Initialize the ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "# Function to load data from JSON file\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "# Function to save labels to a new JSON file\n",
        "def save_labels(output_data, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(output_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Function to calculate ROUGE score and check hallucination\n",
        "def check_hallucination(data):\n",
        "    output_data = []  # List to store the labeled data\n",
        "\n",
        "    for item in data:\n",
        "        question_id = item['question_id']\n",
        "        question = item['question']\n",
        "        original_answer = item['original_answer']['text'][0]  # Get the first text of the original answer\n",
        "\n",
        "        # Dictionary to store results for each question\n",
        "        question_data = {\n",
        "            \"question_id\": question_id,\n",
        "            \"question\": question,\n",
        "            \"original_answer\": item['original_answer'],  # Keep original answer as it is\n",
        "            \"generated_answers\": []\n",
        "        }\n",
        "\n",
        "        for generated_answer in item['generated_answers']:\n",
        "            # Calculate ROUGE-L F1 score\n",
        "            scores = scorer.score(original_answer, generated_answer)\n",
        "            rouge_l_f1 = scores['rougeL'].fmeasure\n",
        "\n",
        "            # Check if hallucinated or not\n",
        "            if rouge_l_f1 < 0.3:\n",
        "                status = \"Hallucinated\"\n",
        "            else:\n",
        "                status = \"Non-Hallucinated\"\n",
        "\n",
        "            # Append the labeled answer with F1 score to the question data\n",
        "            question_data[\"generated_answers\"].append({\n",
        "                \"text\": generated_answer,\n",
        "                \"f1_score\": round(rouge_l_f1, 2),  # Round to 2 decimal places\n",
        "                \"label\": status\n",
        "            })\n",
        "\n",
        "        # Append the question data to the output list\n",
        "        output_data.append(question_data)\n",
        "\n",
        "    return output_data\n",
        "\n",
        "# Load data from JSON file\n",
        "input_file_path = '/content/drive/My Drive/generated_answers_Llama3.1-8b-xquad.json'  # Change this to the path of your input JSON file\n",
        "data = load_data(input_file_path)\n",
        "\n",
        "# Run the function and get labeled data\n",
        "labeled_data = check_hallucination(data)\n",
        "\n",
        "# Save the labeled data to a new JSON file\n",
        "output_file_path = 'labeled_data.json'  # Output file name\n",
        "save_labels(labeled_data, output_file_path)\n",
        "\n",
        "print(f\"Labeled data has been saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwoxX7l6kYfx",
        "outputId": "f3b905f6-da2a-4676-d4f8-52f80e464183"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled data has been saved to labeled_data.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}